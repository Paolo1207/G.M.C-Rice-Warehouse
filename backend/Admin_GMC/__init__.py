# backend/Admin_GMC/__init__.py
from flask import Blueprint, render_template, render_template_string, request, jsonify, session, make_response
from flask_caching import Cache
from sqlalchemy.exc import IntegrityError
from extensions import db
from models import Branch, Product, InventoryItem, RestockLog, User, ForecastData, SalesTransaction, EmailVerification, PasswordReset
from models import ExportLog
from forecasting_service import forecasting_service
from reports_service import reports_service
from auth_helpers import admin_required
from datetime import datetime, timedelta, date
import numpy as np
import json
import os

# Initialize cache
cache = Cache()

# Admin blueprint â€“ templates live in templates/admin/
admin_bp = Blueprint(
    "admin",
    __name__,
    template_folder="templates/admin",
    static_folder="static",
    static_url_path="/admin/static"
)

# ---------- Pages ----------
@admin_bp.route("/dashboard", endpoint="admin_dashboard")
def dashboard():
    return render_template("admin_dashboard.html")

@admin_bp.route("/analytics", endpoint="analytics")
def analytics():
    return render_template("admin_analytics.html")

@admin_bp.route("/deliver", endpoint="deliver")
def deliver():
    return render_template("deliver.html")

@admin_bp.route("/forecast", endpoint="forecast")
def forecast():
    return render_template("admin_forecast.html")

@admin_bp.route("/inventory", endpoint="inventory")
def inventory():
    return render_template("admin_inventory.html")

@admin_bp.route("/notifications", endpoint="notifications")
def notifications():
    return render_template("admin_notifications.html")


@admin_bp.route("/regional", endpoint="regional")
@admin_required
def regional():
    return render_template("admin_regional.html")

@admin_bp.route("/reports", endpoint="reports")
def reports():
    return render_template("admin_reports.html")

@admin_bp.route("/sales", endpoint="sales")
def sales():
    return render_template("admin_sales.html")

@admin_bp.route("/settings", endpoint="settings")
def settings():
    import secrets
    
    # Debug: Check session
    print(f"DEBUG SETTINGS: Session user = {session.get('user')}")
    print(f"DEBUG SETTINGS: Session keys = {list(session.keys())}")
    
    # Manual admin check
    user = session.get('user')
    if not user or user.get('role') != 'admin':
        # Redirect to login instead of JSON error
        return render_template_string("""
            <html>
            <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                <h1 style="color: #d32f2f;">Session Expired</h1>
                <p>Your session has expired. Please log in again.</p>
                <a href="/admin-login" style="background: #2e7d32; color: white; padding: 10px 20px; text-decoration: none; border-radius: 4px;">Go to Login</a>
            </body>
            </html>
        """)
    
    # Generate CSRF token if not exists
    if 'csrf_token' not in session:
        session['csrf_token'] = secrets.token_hex(32)
    
    return render_template("admin_settings.html", csrf_token=session['csrf_token'])

@admin_bp.route("/user", endpoint="user")
def user():
    return render_template("admin_user.html")


# =========================================================
# API: CREATE PRODUCT (+ inventory for a branch)
# =========================================================
@admin_bp.post("/api/products")
def api_create_product():
    """
    Accepts JSON or form data.
    Required: product_name, branch_id OR branch_name
    Optional: category, barcode, sku, desc, warn, auto, margin, batch, stock_kg, unit_price
    If branch_name is provided and doesn't exist, it is created.
    If product already exists (by name), we reuse it; otherwise we create it.
    If inventory record (branch+product) exists, we update the stock/price/batch/thresholds.
    """
    data = request.get_json(silent=True) or request.form

    product_name = (data.get("product_name") or data.get("name") or "").strip()
    if not product_name:
        return jsonify({"ok": False, "error": "product_name is required"}), 400

    # Branch resolution
    branch_id = data.get("branch_id")
    branch = None
    if branch_id:
        branch = Branch.query.get(branch_id)
    else:
        branch_name = (data.get("branch_name") or "").strip()
        if branch_name:
            branch = Branch.query.filter_by(name=branch_name).first()
            if not branch:
                branch = Branch(name=branch_name, status="operational")
                db.session.add(branch)
                db.session.flush()  # get id
        else:
            return jsonify({"ok": False, "error": "branch_id or branch_name is required"}), 400

    # Product resolution / create
    product = Product.query.filter_by(name=product_name).first()
    if not product:
        product = Product(
            name=product_name,
            category=(data.get("category") or "").strip() or None,
            barcode=(data.get("barcode") or "").strip() or None,
            sku=(data.get("sku") or "").strip() or None,
            description=(data.get("desc") or data.get("description") or "").strip() or None,
        )
        db.session.add(product)
        db.session.flush()

    # Inventory: create new entry for (branch, product, batch_code) combination
    stock_kg   = _to_float(data.get("stock_kg") or data.get("stock"))
    unit_price = _to_float(data.get("unit_price") or data.get("price"))
    warn_level = _to_float(data.get("warn"))
    auto_level = _to_float(data.get("auto"))
    margin     = (data.get("margin") or "").strip() or None
    batch_code = (data.get("batch")  or data.get("batch_code") or "").strip() or None
    grn_number = (data.get("grn_number") or data.get("grn") or "").strip() or None

    # Debug logging
    print(f"DEBUG: Creating inventory for product '{product_name}' (id={product.id}), branch '{branch.name}' (id={branch.id}), batch_code='{batch_code}'")

    # Check if this exact combination already exists (branch + product + batch_code)
    # Handle NULL batch_code properly - PostgreSQL treats NULL as distinct in unique constraints
    if batch_code:
        inv = InventoryItem.query.filter_by(
            branch_id=branch.id, 
            product_id=product.id, 
            batch_code=batch_code
        ).first()
        if inv:
            print(f"DEBUG: Found existing inventory item with same batch_code '{batch_code}' (id={inv.id})")
        else:
            print(f"DEBUG: No existing inventory found for batch_code '{batch_code}' - will create new")
    else:
        # For NULL batch_code, check explicitly
        from sqlalchemy import and_
        inv = InventoryItem.query.filter(
            and_(
                InventoryItem.branch_id == branch.id,
                InventoryItem.product_id == product.id,
                InventoryItem.batch_code.is_(None)
            )
        ).first()
        if inv:
            print(f"DEBUG: Found existing inventory item with NULL batch_code (id={inv.id})")
        else:
            print(f"DEBUG: No existing inventory found for NULL batch_code - will create new")
    
    if not inv:
        # Create new inventory item for this batch
        print(f"DEBUG: Creating NEW inventory item for batch_code '{batch_code}'")
        inv = InventoryItem(
            branch_id=branch.id,
            product_id=product.id,
            stock_kg=stock_kg or 0,
            unit_price=unit_price or 0,
            warn_level=warn_level,
            auto_level=auto_level,
            margin=margin,
            batch_code=batch_code,
            grn_number=grn_number,
        )
        db.session.add(inv)
    else:
        # Update existing record with provided fields (if any)
        # IMPORTANT: Only update if the batch_code matches exactly - if user wants different batch, create new
        existing_batch = inv.batch_code or None
        new_batch = batch_code or None
        if existing_batch != new_batch:
            print(f"DEBUG: Existing item has batch_code '{existing_batch}' but user wants '{new_batch}' - creating NEW item instead")
            # Create a new inventory item with the new batch code
            inv = InventoryItem(
                branch_id=branch.id,
                product_id=product.id,
                stock_kg=stock_kg or 0,
                unit_price=unit_price or 0,
                warn_level=warn_level,
                auto_level=auto_level,
                margin=margin,
                batch_code=batch_code,
                grn_number=grn_number,
            )
            db.session.add(inv)
        else:
            print(f"DEBUG: UPDATING existing inventory item (id={inv.id}) with matching batch_code")
            if stock_kg is not None:   inv.stock_kg = stock_kg
            if unit_price is not None: inv.unit_price = unit_price
            if warn_level is not None: inv.warn_level = warn_level
            if auto_level is not None: inv.auto_level = auto_level
            if margin is not None:     inv.margin = margin
            if grn_number is not None: inv.grn_number = grn_number
            # Update timestamp when modifying existing inventory
            from datetime import datetime
            inv.updated_at = datetime.utcnow()

    try:
        db.session.commit()
        
        # Log the product addition activity
        from activity_logger import ActivityLogger
        user_data = session.get('user', {})
        user_id = user_data.get('id')
        # Get current user email from database to ensure accuracy
        current_user = User.query.get(user_id) if user_id else None
        user_email = current_user.email if current_user else user_data.get('email', 'system')
        ActivityLogger.log_product_add(
            user_id=user_id,
            user_email=user_email,
            product_name=product_name,
            branch_id=branch.id,
            details={"category": product.category, "barcode": product.barcode, "sku": product.sku}
        )
        
    except IntegrityError as e:
        db.session.rollback()
        error_msg = str(e.orig) if hasattr(e, 'orig') else str(e)
        # Check if it's the unique constraint violation
        if 'uq_branch_product_batch' in error_msg or 'duplicate key' in error_msg.lower():
            return jsonify({
                "ok": False, 
                "error": f"A product '{product_name}' with batch code '{batch_code or 'N/A'}' already exists in this branch. Please use a different batch code or edit the existing product."
            }), 400
        return jsonify({
            "ok": False, 
            "error": f"Database constraint violation. {error_msg}"
        }), 400

    return jsonify({
        "ok": True,
        "product": {
            "id": product.id,
            "name": product.name,
            "category": product.category,
            "barcode": product.barcode,
            "sku": product.sku,
            "desc": product.description,
        },
        "inventory": inv.to_dict()
    }), 201


# =========================================================
# API: LIST BRANCHES
# =========================================================
@admin_bp.get("/api/branches")
def api_list_branches():
    """Get all branches"""
    try:
        from sqlalchemy import func
        from models import InventoryItem
        branches = Branch.query.all()
        branches_data = []
        for branch in branches:
            try:
                # Compute total stock directly via aggregate to avoid lazy loading issues
                total_stock = (
                    db.session.query(func.coalesce(func.sum(InventoryItem.stock_kg), 0.0))
                    .filter(InventoryItem.branch_id == branch.id)
                    .scalar()
                ) or 0.0
                b = {
                    "id": branch.id,
                    "name": branch.name or "Unknown",
                    "location": branch.location or "N/A",
                    "status": branch.status or "operational",
                    "total_stock_kg": float(total_stock)
                }
                branches_data.append(b)
            except Exception as e:
                print(f"DEBUG: Error calculating total stock for branch {branch.id}: {e}")
                branches_data.append({
                    "id": branch.id,
                    "name": branch.name or "Unknown",
                    "location": branch.location or "N/A",
                    "status": branch.status or "operational",
                    "total_stock_kg": 0
                })
        return jsonify({
            "ok": True,
            "branches": branches_data
        })
    except Exception as e:
        print(f"DEBUG: Error in api_list_branches: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": str(e),
            "branches": []
        }), 500

@admin_bp.get("/api/branches/<int:branch_id>/inventory")
def api_branch_inventory(branch_id):
    """Get inventory for a specific branch"""
    from sqlalchemy.orm import joinedload
    
    branch = Branch.query.get_or_404(branch_id)
    
    # Get all inventory items for this branch with product information
    items = InventoryItem.query.filter_by(branch_id=branch_id).all()
    
    inventory_data = []
    for item in items:
        inventory_data.append({
            "id": item.id,
            "product_name": item.product.name if item.product else "Unknown",
            "variant": item.product.name if item.product else "Unknown",
            "stock": item.stock_kg,
            "price": item.unit_price,
            "status": "available" if (item.stock_kg or 0) > 0 else "out_of_stock",
            "batch": item.batch_code,
            "batch_code": item.batch_code,
            "grn": item.grn_number,
            "grn_number": item.grn_number,
            "warn": item.warn_level,
            "warn_level": item.warn_level,
            "auto": item.auto_level,
            "auto_level": item.auto_level,
            "updated_at": item.updated_at.isoformat() if item.updated_at else None,
            "last_updated": item.updated_at.isoformat() if item.updated_at else None,
        })
    
    return jsonify({
        "ok": True,
        "branch": branch.to_dict(),
        "items": inventory_data
    })

@admin_bp.get("/api/products/<int:product_id>/batch-codes")
def api_product_batch_codes(product_id):
    """Get batch codes for a specific product, optionally filtered by branch"""
    # Get branch filter from query params
    branch_id = request.args.get("branch_id", type=int)
    branch_name = request.args.get("branch_name", type=str)
    
    # Build query for batch codes
    query = db.session.query(
        InventoryItem.batch_code
    ).filter(
        InventoryItem.product_id == product_id,
        InventoryItem.batch_code.isnot(None),
        InventoryItem.batch_code != ''
    )
    
    # Filter by branch if provided
    if branch_id:
        query = query.filter(InventoryItem.branch_id == branch_id)
    elif branch_name:
        branch = Branch.query.filter_by(name=branch_name).first()
        if branch:
            query = query.filter(InventoryItem.branch_id == branch.id)
    
    # Get distinct batch codes
    batch_codes = query.distinct().all()
    batch_codes_list = [row[0] for row in batch_codes if row[0]]
    
    return jsonify({
        "ok": True,
        "batch_codes": batch_codes_list
    })

# =========================================================
# API: NOTIFICATIONS
# =========================================================
@admin_bp.get("/api/notifications")
def api_list_notifications():
    """Get all admin notifications"""
    from models import Notification
    notifications = Notification.query.order_by(Notification.created_at.desc()).all()
    return jsonify({
        "ok": True,
        "notifications": [notification.to_dict() for notification in notifications]
    })

@admin_bp.post("/api/notifications")
def api_create_notification():
    """Create a new notification"""
    from models import Notification, db
    from datetime import datetime
    
    data = request.get_json()
    if not data:
        return jsonify({"ok": False, "error": "No data provided"}), 400
    
    try:
        notification = Notification(
            type=data.get('type'),
            branch_id=data.get('branch_id'),
            date=datetime.strptime(data.get('date'), '%Y-%m-%d').date(),
            message=data.get('message'),
            sender='Admin',
            status='unread',
            created_at=datetime.now()
        )
        
        db.session.add(notification)
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "message": "Notification created successfully",
            "notification": notification.to_dict()
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({"ok": False, "error": str(e)}), 500

@admin_bp.patch("/api/notifications/<int:notification_id>/read")
def api_mark_notification_read(notification_id):
    """Mark a notification as read"""
    from models import Notification, db
    
    try:
        notification = Notification.query.get(notification_id)
        if not notification:
            return jsonify({"ok": False, "error": "Notification not found"}), 404
        
        notification.status = 'read'
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "message": "Notification marked as read"
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({"ok": False, "error": str(e)}), 500

@admin_bp.delete("/api/notifications/<int:notification_id>")
def api_delete_notification(notification_id):
    """Delete a notification"""
    from models import Notification, db
    
    try:
        notification = Notification.query.get(notification_id)
        if not notification:
            return jsonify({"ok": False, "error": "Notification not found"}), 404
        
        db.session.delete(notification)
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "message": "Notification deleted successfully"
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({"ok": False, "error": str(e)}), 500

# =========================================================
# API: LIST PRODUCTS / INVENTORY for a branch
# =========================================================
@admin_bp.get("/api/products")
def api_list_products():
    """Get all products that have inventory items, optionally filtered by branch"""
    branch_id = request.args.get("branch_id", type=int)
    
    if branch_id:
        # Get products that have inventory items in the specific branch
        products_with_inventory = (
            Product.query
            .join(InventoryItem)
            .filter(InventoryItem.branch_id == branch_id)
            .distinct()
            .all()
        )
    else:
        # Get all products that have inventory items in any branch
        products_with_inventory = (
            Product.query
            .join(InventoryItem)
            .distinct()
            .all()
        )
    
    return jsonify({
        "ok": True,
        "products": [product.to_dict() for product in products_with_inventory]
    })

@admin_bp.get("/api/products/branch")
def api_list_products_by_branch():
    """
    Query params:
      - branch_id (recommended) or branch_name
      - q (optional text filter by product name)
    Returns inventory items (joined with product) for that branch.
    """
    branch = None
    branch_id = request.args.get("branch_id", type=int)
    if branch_id:
        branch = Branch.query.get(branch_id)
    else:
        branch_name = (request.args.get("branch_name") or "").strip()
        if branch_name:
            branch = Branch.query.filter_by(name=branch_name).first()
    if not branch:
        return jsonify({"ok": False, "error": "Branch not found"}), 404

    q = (request.args.get("q") or "").strip().lower()
    from sqlalchemy.orm import load_only
    query = (
        InventoryItem.query
        .options(
            load_only(
                InventoryItem.id,
                InventoryItem.branch_id,
                InventoryItem.product_id,
                InventoryItem.stock_kg,
                InventoryItem.unit_price,
                InventoryItem.batch_code,
                InventoryItem.grn_number,
                InventoryItem.warn_level,
                InventoryItem.auto_level,
                InventoryItem.margin,
            )
        )
        .filter_by(branch_id=branch.id)
        .join(Product)
        .order_by(Product.name, InventoryItem.batch_code)  # Order by product name and batch for consistent display
    )
    if q:
        query = query.filter(Product.name.ilike(f"%{q}%"))

    items = query.all()
    print(f"DEBUG: api_list_products_by_branch: Found {len(items)} inventory items for branch '{branch.name}' (id={branch.id})")
    
    # Build a dict manually with all fields including grn_number
    out_items = []
    for it in items:
        try:
            out_items.append({
                "id": it.id,
                "branch_id": it.branch_id,
                "product_id": it.product_id,
                "product_name": it.product.name if it.product else None,
                "variant": it.product.name if it.product else None,
                "category": it.product.category if it.product else None,
                "barcode": it.product.barcode if it.product else None,
                "sku": it.product.sku if it.product else None,
                "desc": it.product.description if it.product else None,
                "stock": it.stock_kg,
                "stock_kg": it.stock_kg,
                "price": it.unit_price,
                "unit_price": it.unit_price,
                "batch": it.batch_code,
                "batch_code": it.batch_code,
                "grn": getattr(it, 'grn_number', None),
                "grn_number": getattr(it, 'grn_number', None),
                "warn": it.warn_level,
                "warn_level": it.warn_level,
                "auto": it.auto_level,
                "auto_level": it.auto_level,
                "margin": it.margin,
                "status": ("out" if (it.stock_kg or 0) <= 0 else ("low" if (it.warn_level is not None and (it.stock_kg or 0) < it.warn_level) else "available")),
                "updated_at": it.updated_at.isoformat() if it.updated_at else None,
                "last_updated": it.updated_at.isoformat() if it.updated_at else None,
            })
            print(f"DEBUG: Added item: product='{it.product.name if it.product else None}', batch='{it.batch_code}', stock={it.stock_kg}")
        except Exception as e:
            print(f"DEBUG: serialize inventory item {it.id} failed: {e}")
            import traceback
            traceback.print_exc()
    return jsonify({
        "ok": True,
        "branch": {"id": branch.id, "name": branch.name},
        "items": out_items
    })


# =========================================================
# API: UPDATE (EDIT) a single Inventory row + its Product
# URL: PATCH /admin/api/products/<inventory_id>
# =========================================================
@admin_bp.route("/api/products/<int:inventory_id>", methods=["PATCH"])
def api_update_inventory_item(inventory_id: int):
    """
    Accepts JSON body. Editable keys:
      product_name, category, barcode, sku, desc,
      stock_kg, unit_price, batch, warn, auto, margin

    Returns the refreshed inventory item (InventoryItem.to_dict()).
    """
    data = request.get_json(silent=True) or {}

    inv: InventoryItem = InventoryItem.query.get_or_404(inventory_id)
    prod: Product = inv.product

    def set_if(d, key, obj, attr, conv=lambda x: x):
        if key in d and d[key] is not None:
            setattr(obj, attr, conv(d[key]))

    # --- Update Product fields ---
    set_if(data, "product_name", prod, "name", str)
    set_if(data, "category",     prod, "category", str)
    set_if(data, "barcode",      prod, "barcode", str)
    set_if(data, "sku",          prod, "sku", str)
    set_if(data, "desc",         prod, "description", str)

    # --- Update Inventory fields ---
    set_if(data, "stock_kg",   inv, "stock_kg", float)
    set_if(data, "unit_price", inv, "unit_price", float)
    set_if(data, "batch",      inv, "batch_code", str)
    set_if(data, "grn",        inv, "grn_number", str)
    set_if(data, "warn",       inv, "warn_level", float)
    set_if(data, "auto",       inv, "auto_level", float)
    set_if(data, "margin",     inv, "margin", str)
    
    # Update timestamp when any inventory field is modified
    if any(key in data for key in ["stock_kg", "unit_price", "batch", "grn", "warn", "auto", "margin"]):
        from datetime import datetime
        inv.updated_at = datetime.utcnow()

    try:
        db.session.commit()
        
        # Log the product edit activity
        from activity_logger import ActivityLogger
        user_data = session.get('user', {})
        user_id = user_data.get('id')
        # Get current user email from database to ensure accuracy
        current_user = User.query.get(user_id) if user_id else None
        user_email = current_user.email if current_user else user_data.get('email', 'system')
        ActivityLogger.log_product_edit(
            user_id=user_id,
            user_email=user_email,
            product_name=prod.name,
            branch_id=inv.branch_id,
            changes=data
        )
        
    except IntegrityError as e:
        # Handle possible name uniqueness conflicts, etc.
        db.session.rollback()
        return jsonify({"ok": False, "error": "Integrity error", "detail": str(e.orig)}), 409

    return jsonify({"ok": True, "item": inv.to_dict()})


# ---------- helpers ----------
def _to_float(v):
    if v is None or v == "":
        return None
    try:
        return float(v)
    except ValueError:
        return None
# =========================================================
# API: DELETE a single Inventory row (+ optionally its Product if orphaned)
# URL: DELETE /admin/api/products/<inventory_id>?delete_product_if_orphan=1
# =========================================================
@admin_bp.delete("/api/products/<int:inventory_id>")
def api_delete_inventory_item(inventory_id: int):
    """
    Deletes one inventory_items row by its id.
    If the associated product would become orphaned (no other inventory rows),
    and query param delete_product_if_orphan=1, the product is also deleted.

    Returns:
      { ok: true, deleted_inventory_id, deleted_product (bool), product_id }
    """
    inv: InventoryItem = InventoryItem.query.get_or_404(inventory_id)
    prod: Product = inv.product

    # read optional flag
    delete_product_if_orphan = request.args.get("delete_product_if_orphan", "1") in ("1", "true", "True")

    # delete the inventory record
    db.session.delete(inv)
    db.session.flush()  # so we can check remaining product relations in the same txn

    deleted_product = False
    product_id = prod.id if prod else None

    if prod and delete_product_if_orphan:
        # Is this product still referenced by any other inventory rows?
        still_used = InventoryItem.query.filter_by(product_id=prod.id).count()
        if still_used == 0:
            db.session.delete(prod)
            deleted_product = True

    db.session.commit()
    
    # Log the product deletion activity
    from activity_logger import ActivityLogger
    user_data = session.get('user', {})
    user_id = user_data.get('id')
    # Get current user email from database to ensure accuracy
    current_user = User.query.get(user_id) if user_id else None
    user_email = current_user.email if current_user else user_data.get('email', 'system')
    ActivityLogger.log_product_delete(
        user_id=user_id,
        user_email=user_email,
        product_name=prod.name if prod else "Unknown Product",
        branch_id=inv.branch_id
    )

    return jsonify({
        "ok": True,
        "deleted_inventory_id": inventory_id,
        "deleted_product": deleted_product,
        "product_id": product_id,
    })
# =========================================================
# API: RESTOCK a single Inventory row (also creates RestockLog)
# URL: POST /admin/api/inventory/<inventory_id>/restock
# Body: { quantity, supplier?, notes?, date? }
# =========================================================
@admin_bp.post("/api/inventory/<int:inventory_id>/restock")
def api_restock_inventory_item(inventory_id: int):
    from datetime import datetime

    data = request.get_json(silent=True) or request.form
    qty = _to_float(data.get("quantity") or data.get("qty") or data.get("qty_kg"))
    if qty is None or qty <= 0:
        return jsonify({"ok": False, "error": "quantity must be a positive number"}), 400

    # Avoid selecting undefined DB columns (e.g., grn_number) on deployments where
    # the column isn't present yet. Load only the fields we need.
    from sqlalchemy.orm import load_only
    inv: InventoryItem = (
        db.session.query(InventoryItem)
        .options(
            load_only(
                InventoryItem.id,
                InventoryItem.branch_id,
                InventoryItem.product_id,
                InventoryItem.stock_kg,
                InventoryItem.unit_price,
                InventoryItem.warn_level,
                InventoryItem.auto_level,
                InventoryItem.margin,
                InventoryItem.batch_code,
            )
        )
        .filter(InventoryItem.id == inventory_id)
        .first()
    )
    if not inv:
        return jsonify({"ok": False, "error": "Inventory item not found"}), 404
    batch_code = (data.get("batch_code") or "").strip()
    
    if not batch_code:
        return jsonify({"ok": False, "error": "batch_code is required"}), 400

    supplier = (data.get("supplier") or "").strip() or None
    note     = (data.get("notes") or data.get("note") or "").strip() or None

    # Optional override date (YYYY-MM-DD). If omitted or empty, always use current time.
    # If date is provided and it's today, use current time. Otherwise, use midnight of that date.
    # IMPORTANT: Always use current time unless a valid past date is explicitly provided.
    created_at = None
    date_str = data.get("date") or ""
    date_str = date_str.strip() if isinstance(date_str, str) else ""
    
    if date_str:
        try:
            date_only = datetime.strptime(date_str, "%Y-%m-%d").date()
            today = datetime.utcnow().date()
            # If the date is today, use current time. Otherwise, use midnight of that date.
            if date_only == today:
                created_at = datetime.utcnow()  # Use current time for today's date
            else:
                created_at = datetime.combine(date_only, datetime.min.time())  # Use midnight for past dates
        except (ValueError, TypeError):
            return jsonify({"ok": False, "error": "date must be YYYY-MM-DD"}), 400
    # If no date provided, created_at remains None and will use datetime.utcnow() below

    # Check if inventory item with this batch code already exists
    existing_inv = InventoryItem.query.filter_by(
        branch_id=inv.branch_id,
        product_id=inv.product_id,
        batch_code=batch_code
    ).first()

    if existing_inv:
        # Add to existing batch
        existing_inv.stock_kg = (existing_inv.stock_kg or 0) + qty
        # Update timestamp when restocking existing inventory
        existing_inv.updated_at = datetime.utcnow()
        target_inv = existing_inv
    else:
        # Create new inventory item with new batch code
        new_inv = InventoryItem(
            branch_id=inv.branch_id,
            product_id=inv.product_id,
            stock_kg=qty,
            unit_price=inv.unit_price,
            warn_level=inv.warn_level,
            auto_level=inv.auto_level,
            margin=inv.margin,
            batch_code=batch_code,
        )
        db.session.add(new_inv)
        db.session.flush()  # Get the ID
        target_inv = new_inv

    # Create a restock log row
    # Always use current time unless a valid past date was explicitly provided
    from models import RestockLog
    # IMPORTANT: Call datetime.utcnow() right here to capture the exact moment of restock
    # Do NOT rely on model default - explicitly set the timestamp
    if created_at is None:
        created_at = datetime.utcnow()
    
    log = RestockLog(
        inventory_item_id=target_inv.id,
        qty_kg=qty,
        supplier=supplier,
        note=note
    )
    # CRITICAL: Explicitly set created_at AFTER object creation to override any defaults
    # This ensures we use the exact timestamp we calculated, not a model default
    log.created_at = created_at
    db.session.add(log)

    try:
        db.session.commit()
        
        # Refresh the log from database to ensure we have the actual stored timestamp
        db.session.refresh(log)
        
        # Log the restock activity
        from activity_logger import ActivityLogger
        user_data = session.get('user', {})
        user_id = user_data.get('id')
        # Get current user email from database to ensure accuracy
        current_user = User.query.get(user_id) if user_id else None
        user_email = current_user.email if current_user else user_data.get('email', 'system')
        ActivityLogger.log_restock(
            user_id=user_id,
            user_email=user_email,
            product_name=inv.product.name if inv.product else "Unknown Product",
            quantity=qty,
            branch_id=inv.branch_id
        )
        
    except IntegrityError as e:
        db.session.rollback()
        return jsonify({"ok": False, "error": "Integrity error", "detail": str(e.orig)}), 400

    # Re-fetch lightweight view for response without touching missing columns
    fresh = (
        db.session.query(InventoryItem)
        .options(load_only(
            InventoryItem.id,
            InventoryItem.branch_id,
            InventoryItem.product_id,
            InventoryItem.stock_kg,
            InventoryItem.unit_price,
            InventoryItem.warn_level,
            InventoryItem.auto_level,
            InventoryItem.margin,
            InventoryItem.batch_code,
        ))
        .filter(InventoryItem.id == target_inv.id)
        .first()
    )
    item_dict = {
        "id": fresh.id,
        "branch_id": fresh.branch_id,
        "product_id": fresh.product_id,
        "product_name": fresh.product.name if fresh.product else None,
        "variant": fresh.product.name if fresh.product else None,
        "stock": fresh.stock_kg,
        "price": fresh.unit_price,
        "batch": fresh.batch_code,
        "warn": fresh.warn_level,
        "auto": fresh.auto_level,
        "margin": fresh.margin,
        "status": ("out" if (fresh.stock_kg or 0) <= 0 else ("low" if (fresh.warn_level is not None and (fresh.stock_kg or 0) < fresh.warn_level) else "available")),
        "updated_at": fresh.updated_at.isoformat() if fresh.updated_at else None,
    }
    return jsonify({"ok": True, "item": item_dict, "log": log.to_dict()}), 201


# =========================================================
# API: FETCH RESTOCK LOGS for one inventory row
# URL: GET /admin/api/inventory/<inventory_id>/logs
# =========================================================
@admin_bp.get("/api/inventory/<int:inventory_id>/logs")
def api_get_inventory_logs(inventory_id: int):
    from models import RestockLog
    from sqlalchemy.orm import load_only
    inv = (
        db.session.query(InventoryItem)
        .options(load_only(InventoryItem.id))
        .filter(InventoryItem.id == inventory_id)
        .first()
    )
    if not inv:
        return jsonify({"ok": False, "error": "Inventory item not found"}), 404
    logs = (
        RestockLog.query
        .filter_by(inventory_item_id=inv.id)
        .order_by(RestockLog.created_at.desc())
        .all()
    )
    return jsonify({"ok": True, "inventory_id": inv.id, "logs": [l.to_dict() for l in logs]})

# ========== FORECASTING API ENDPOINTS ==========

@admin_bp.post("/api/forecast/generate")
def api_generate_forecast():
    """Generate forecast for a specific product and branch"""
    from models import ForecastData, SalesTransaction
    from forecasting_service import forecasting_service
    from datetime import datetime, timedelta
    from forecasting_service import rf_forecast, snaive_forecast
    
    data = request.get_json()
    branch_id = data.get('branch_id')
    product_id = data.get('product_id')
    model_type = data.get('model_type', 'ARIMA')
    periods = data.get('periods', 30)
    
    if not branch_id or not product_id:
        return jsonify({"ok": False, "error": "branch_id and product_id are required"}), 400
    
    # Get historical sales data - 2 to 3 years back (using 2.5 years = ~912 days)
    date_threshold = datetime.now() - timedelta(days=912)  # Approximately 2.5 years
    sales_data = (
        SalesTransaction.query
        .filter_by(branch_id=branch_id, product_id=product_id)
        .filter(SalesTransaction.transaction_date >= date_threshold)
        .order_by(SalesTransaction.transaction_date.desc())
        .all()
    )
    
    # Convert to proper format for forecasting service
    historical_data = []
    for sale in sales_data:
        historical_data.append({
            "transaction_date": sale.transaction_date.strftime("%Y-%m-%d %H:%M:%S"),
            "quantity_sold": float(sale.quantity_sold)
        })
    
    # If no sales data, create some dummy data based on inventory
    if not historical_data:
        # Get inventory item to estimate base demand
        inventory_item = InventoryItem.query.filter_by(
            branch_id=branch_id, product_id=product_id
        ).first()
        
        if inventory_item:
            # Create dummy sales data based on current stock
            base_demand = max(10, inventory_item.stock_kg * 0.1)  # 10% of stock as daily demand
            historical_data = []
            
            for i in range(30):  # Last 30 days
                # Generate random variation, ensuring no NaN values
                random_variation = np.random.normal(0, base_demand * 0.2)
                if np.isnan(random_variation):
                    random_variation = 0
                
                quantity_sold = base_demand + random_variation
                if np.isnan(quantity_sold) or quantity_sold < 0:
                    quantity_sold = base_demand
                
                historical_data.append({
                    "transaction_date": (datetime.now() - timedelta(days=30-i)).strftime("%Y-%m-%d %H:%M:%S"),
                    "quantity_sold": float(quantity_sold)
                })
        else:
            return jsonify({"ok": False, "error": "No inventory data found for this product"}), 400
    
    # Generate forecast with ETL pipeline, train/test split, training, and model selection
    try:
        # Use model selection: train all models, evaluate, and select best
        # If user specified a model type, use it; otherwise auto-select best model
        forecast_result = forecasting_service.generate_forecast_with_model_selection(
            historical_data, 
            periods, 
            requested_model=model_type if model_type else None
        )
        
        if not forecast_result:
            return jsonify({"ok": False, "error": "Forecast generation failed - no valid model"}), 500
        
        # Add forecast start date for frontend
        forecast_result['forecast_start_date'] = datetime.now().date().isoformat()
        
    except Exception as e:
        print(f"Forecast generation error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": f"Forecast generation failed: {str(e)}"}), 500
    
    # Store forecast results in database
    forecast_records = []
    start_date = datetime.now().date()
    
    # Handle confidence intervals that might be None for RF and Seasonal models
    confidence_lower = forecast_result.get('confidence_lower', [])
    confidence_upper = forecast_result.get('confidence_upper', [])
    
    # If confidence intervals are None, create default values
    if confidence_lower is None:
        confidence_lower = [None] * len(forecast_result['forecast_values'])
    if confidence_upper is None:
        confidence_upper = [None] * len(forecast_result['forecast_values'])
    
    for i, (predicted, lower, upper) in enumerate(zip(
        forecast_result['forecast_values'],
        confidence_lower,
        confidence_upper
    )):
        forecast_date = start_date + timedelta(days=i)
        
        # Handle NaN and None values in forecast results
        predicted = float(predicted) if predicted is not None and not np.isnan(predicted) else 0.0
        lower = float(lower) if lower is not None and not np.isnan(lower) else max(0, predicted * 0.7)
        upper = float(upper) if upper is not None and not np.isnan(upper) else predicted * 1.3
        accuracy_score = float(forecast_result.get('accuracy_score', 0.5))
        if np.isnan(accuracy_score):
            accuracy_score = 0.5
        
        # Check if forecast already exists
        existing = ForecastData.query.filter_by(
            branch_id=branch_id,
            product_id=product_id,
            forecast_date=forecast_date,
            forecast_period='daily'
        ).first()
        
        if not existing:
            forecast_record = ForecastData(
                branch_id=branch_id,
                product_id=product_id,
                forecast_date=forecast_date,
                forecast_period='daily',
                predicted_demand=predicted,
                confidence_interval_lower=lower,
                confidence_interval_upper=upper,
                model_type=forecast_result['model_type'],
                accuracy_score=accuracy_score
            )
            db.session.add(forecast_record)
            forecast_records.append(forecast_record)
    
    db.session.commit()
    
    # Clean forecast result to remove any NaN values
    # Handle None confidence intervals for RF and Seasonal models
    confidence_lower = forecast_result.get('confidence_lower', [])
    confidence_upper = forecast_result.get('confidence_upper', [])
    
    if confidence_lower is None:
        confidence_lower = []
    if confidence_upper is None:
        confidence_upper = []
    
    # Calculate forecast start date (tomorrow)
    forecast_start_date = (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d')
    
    cleaned_forecast = {
        "model_type": forecast_result.get('model_type', 'ARIMA'),
        "accuracy_score": float(forecast_result.get('accuracy_score', 0.5)) if not np.isnan(forecast_result.get('accuracy_score', 0.5)) else 0.5,
        "forecast_values": [float(v) if not np.isnan(v) else 0.0 for v in forecast_result.get('forecast_values', [])],
        "confidence_lower": [float(v) if v is not None and not np.isnan(v) else 0.0 for v in confidence_lower],
        "confidence_upper": [float(v) if v is not None and not np.isnan(v) else 0.0 for v in confidence_upper],
        "forecast_start_date": forecast_start_date
    }
    
    return jsonify({
        "ok": True,
        "forecast": cleaned_forecast,
        "records_created": len(forecast_records),
        "branch_id": branch_id,
        "product_id": product_id
    })

@admin_bp.get("/api/forecast/<int:branch_id>/<int:product_id>")
def api_get_forecast(branch_id: int, product_id: int):
    """Get existing forecast data for a product"""
    from models import ForecastData
    from datetime import datetime, timedelta
    
    # Get forecasts for the next 30 days
    end_date = datetime.now().date() + timedelta(days=30)
    
    forecasts = (
        ForecastData.query
        .filter_by(branch_id=branch_id, product_id=product_id)
        .filter(ForecastData.forecast_date >= datetime.now().date())
        .filter(ForecastData.forecast_date <= end_date)
        .order_by(ForecastData.forecast_date)
        .all()
    )
    
    return jsonify({
        "ok": True,
        "forecasts": [f.to_dict() for f in forecasts],
        "branch_id": branch_id,
        "product_id": product_id
    })

@admin_bp.get("/api/forecast/dashboard")
def api_forecast_dashboard():
    """Get forecast dashboard data for all branches"""
    from models import ForecastData, Branch, Product
    from datetime import datetime, timedelta
    
    # Get recent forecasts (next 7 days)
    end_date = datetime.now().date() + timedelta(days=7)
    
    forecasts = (
        ForecastData.query
        .join(Branch)
        .join(Product)
        .filter(ForecastData.forecast_date >= datetime.now().date())
        .filter(ForecastData.forecast_date <= end_date)
        .order_by(ForecastData.forecast_date)
        .all()
    )
    
    # Group by branch and product
    dashboard_data = {}
    for forecast in forecasts:
        branch_name = forecast.branch.name
        product_name = forecast.product.name
        
        if branch_name not in dashboard_data:
            dashboard_data[branch_name] = {}
        
        if product_name not in dashboard_data[branch_name]:
            dashboard_data[branch_name][product_name] = []
        
        dashboard_data[branch_name][product_name].append(forecast.to_dict())
    
    return jsonify({
        "ok": True,
        "dashboard_data": dashboard_data,
        "total_forecasts": len(forecasts)
    })

# ========== SALES TRANSACTION API ==========

@admin_bp.post("/api/sales/transaction")
def api_create_sales_transaction():
    """Create a new sales transaction"""
    from models import SalesTransaction
    
    data = request.get_json()
    
    # Validate required fields
    required_fields = ['branch_id', 'product_id', 'quantity_sold', 'unit_price']
    for field in required_fields:
        if field not in data:
            return jsonify({"ok": False, "error": f"{field} is required"}), 400
    
    # Calculate total amount
    total_amount = data['quantity_sold'] * data['unit_price']
    
    # Create transaction
    transaction = SalesTransaction(
        branch_id=data['branch_id'],
        product_id=data['product_id'],
        quantity_sold=data['quantity_sold'],
        unit_price=data['unit_price'],
        total_amount=total_amount,
        customer_name=data.get('customer_name'),
        customer_contact=data.get('customer_contact')
    )
    
    db.session.add(transaction)
    db.session.commit()
    
    return jsonify({
        "ok": True,
        "transaction": transaction.to_dict(),
        "message": "Sales transaction created successfully"
    })

# ========== SALES MODULE (Admin) ==========

@admin_bp.get("/api/sales")
def api_sales_list():
    """Rows from sales_transactions joined with products and branches.
    Query: days|from|to, branch_id, product_id, page, limit
    """
    from sqlalchemy import func, and_
    from models import Branch, Product
    page = request.args.get('page', 1, type=int)
    limit = request.args.get('limit', 50, type=int)
    days = request.args.get('days', type=int)
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    to = request.args.get('to')
    frm = request.args.get('from')

    end = datetime.utcnow()
    if to:
        try: 
            # Parse the date and set to end of day (23:59:59.999999) to include the full day
            end_date = datetime.strptime(to, '%Y-%m-%d')
            end = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)
        except: pass
    start = end - timedelta(days=days or 30)
    if frm:
        try: 
            # Parse the date and set to start of day (00:00:00) to include the full day
            start_date = datetime.strptime(frm, '%Y-%m-%d')
            start = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
        except: pass

    # Get batch code from inventory items (simplified: get first batch for each product/branch)
    # Using a simpler approach: get the first inventory item's batch_code for each product/branch
    from sqlalchemy import func
    first_batch = (
        db.session.query(
            InventoryItem.product_id,
            InventoryItem.branch_id,
            InventoryItem.batch_code,
            func.min(InventoryItem.id).label('min_id')
        )
        .group_by(InventoryItem.product_id, InventoryItem.branch_id, InventoryItem.batch_code)
        .subquery()
    )
    
    # Get the first batch (lowest ID = oldest) for each product/branch
    batch_lookup = (
        db.session.query(
            first_batch.c.product_id,
            first_batch.c.branch_id,
            first_batch.c.batch_code
        )
        .distinct(first_batch.c.product_id, first_batch.c.branch_id)
        .order_by(
            first_batch.c.product_id,
            first_batch.c.branch_id,
            first_batch.c.min_id.asc()
        )
        .subquery()
    )
    
    q = db.session.query(
        SalesTransaction.id,
        SalesTransaction.transaction_date,
        SalesTransaction.branch_id,
        SalesTransaction.product_id,
        SalesTransaction.quantity_sold,
        SalesTransaction.total_amount,
        SalesTransaction.batch_code,  # Get batch_code directly from SalesTransaction
        Product.name.label('product_name'),
        Branch.name.label('branch_name'),
        batch_lookup.c.batch_code.label('fallback_batch_code')  # Fallback if SalesTransaction.batch_code is NULL
    ).join(Product, Product.id == SalesTransaction.product_id)
    q = q.join(Branch, Branch.id == SalesTransaction.branch_id)
    q = q.outerjoin(
        batch_lookup,
        (batch_lookup.c.product_id == SalesTransaction.product_id) & 
        (batch_lookup.c.branch_id == SalesTransaction.branch_id)
    )
    q = q.filter(and_(SalesTransaction.transaction_date >= start, SalesTransaction.transaction_date <= end))
    if branch_id: q = q.filter(SalesTransaction.branch_id == branch_id)
    if product_id: q = q.filter(SalesTransaction.product_id == product_id)

    total_rows = q.count()
    rows = q.order_by(SalesTransaction.transaction_date.desc()).offset((page-1)*limit).limit(limit).all()

    totals = db.session.query(
        func.sum(SalesTransaction.quantity_sold), func.sum(SalesTransaction.total_amount)
    ).filter(and_(SalesTransaction.transaction_date >= start, SalesTransaction.transaction_date <= end))
    if branch_id: totals = totals.filter(SalesTransaction.branch_id == branch_id)
    if product_id: totals = totals.filter(SalesTransaction.product_id == product_id)
    qty_sum, amt_sum = totals.first()

    def serialize(r):
        # Use batch_code from SalesTransaction if available, otherwise use fallback
        batch_code = r.batch_code if hasattr(r, 'batch_code') and r.batch_code else None
        if not batch_code and hasattr(r, 'fallback_batch_code'):
            batch_code = r.fallback_batch_code
        
        return {
            "id": r.id,
            "date": r.transaction_date.strftime('%Y-%m-%d'),
            "datetime": r.transaction_date.strftime('%Y-%m-%d %H:%M:%S'),  # Include full datetime
            "transaction_date": r.transaction_date.isoformat(),  # ISO format for JavaScript parsing
            "branch_id": r.branch_id,
            "branch_name": r.branch_name,
            "product_id": r.product_id,
            "product_name": r.product_name,
            "qty": float(r.quantity_sold or 0),
            "amount": float(r.total_amount or 0),
            "batch_code": batch_code,
        }

    return jsonify({
        "ok": True,
        "rows": [serialize(r) for r in rows],
        "meta": {"page": page, "total_rows": total_rows},
        "totals": {"qty": float(qty_sum or 0), "amount": float(amt_sum or 0)}
    })

@admin_bp.get("/api/sales/kpis")
def api_sales_kpis():
    """Return month sales, units sold, avg order value for date window."""
    from sqlalchemy import func, and_
    days = request.args.get('days', type=int)
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    to = request.args.get('to')
    frm = request.args.get('from')
    
    end = datetime.utcnow()
    if to:
        try: 
            # Parse the date and set to end of day (23:59:59.999999) to include the full day
            end_date = datetime.strptime(to, '%Y-%m-%d')
            end = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)
        except: pass
    start = end - timedelta(days=days or 30)
    if frm:
        try: 
            # Parse the date and set to start of day (00:00:00) to include the full day
            start_date = datetime.strptime(frm, '%Y-%m-%d')
            start = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
        except: pass
    
    q = db.session.query(func.sum(SalesTransaction.total_amount), func.sum(SalesTransaction.quantity_sold), func.count(SalesTransaction.id))
    q = q.filter(and_(SalesTransaction.transaction_date >= start, SalesTransaction.transaction_date <= end))
    if branch_id: q = q.filter(SalesTransaction.branch_id == branch_id)
    if product_id: q = q.filter(SalesTransaction.product_id == product_id)
    amt, qty, orders = q.first()
    avg = (float(amt or 0) / orders) if orders else 0
    return jsonify({"ok": True, "kpis": {"month_sales": float(amt or 0), "units_sold": float(qty or 0), "avg_order_value": round(avg,2)}})

@admin_bp.get("/api/sales/trend")
def api_sales_trend():
    try:
        from sqlalchemy import func, and_
        from datetime import timezone, timedelta as td
        granularity = request.args.get('granularity', 'daily')
        days = request.args.get('days', type=int)
        branch_id = request.args.get('branch_id', type=int)
        product_id = request.args.get('product_id', type=int)
        to = request.args.get('to')
        frm = request.args.get('from')
        
        # Use Philippines timezone (UTC+8) for date calculations to include today's sales
        ph_tz = timezone(td(hours=8))
        now_ph = datetime.now(ph_tz)
        end = now_ph.date()  # Today in Philippines time
        
        if to:
            try: end = datetime.strptime(to, '%Y-%m-%d').date()
            except: pass
        start = end - td(days=days or 90)
        if frm:
            try: start = datetime.strptime(frm, '%Y-%m-%d').date()
            except: pass
        if granularity == 'daily':
            date_expr = func.date(SalesTransaction.transaction_date)
        elif granularity == 'week':
            date_expr = func.to_char(SalesTransaction.transaction_date, 'IYYY-IW')
        else:
            date_expr = func.to_char(SalesTransaction.transaction_date, 'YYYY-MM')
        q = db.session.query(date_expr.label('period'), SalesTransaction.branch_id, func.sum(SalesTransaction.total_amount).label('amt'))
        q = q.filter(and_(func.date(SalesTransaction.transaction_date) >= start, func.date(SalesTransaction.transaction_date) <= end))
        if branch_id: q = q.filter(SalesTransaction.branch_id == branch_id)
        if product_id: q = q.filter(SalesTransaction.product_id == product_id)
        q = q.group_by('period', SalesTransaction.branch_id).order_by('period')
        rows = q.all()
        
        # Normalize periods to strings for consistent matching
        out = {}
        for period, bid, amt in rows:
            # Convert period to string format (YYYY-MM-DD for daily)
            if granularity == 'daily':
                if isinstance(period, date):
                    period_key = period.strftime('%Y-%m-%d')
                else:
                    period_key = str(period)
            else:
                period_key = str(period)
            out.setdefault(period_key, {})[int(bid)] = float(amt or 0)
        
        # Generate all dates in range (including today) to ensure complete date range
        all_dates = []
        current_date = start
        while current_date <= end:
            if granularity == 'daily':
                all_dates.append(current_date)
                current_date += td(days=1)
            elif granularity == 'week':
                # For weekly, add week start dates
                week_start = current_date - td(days=current_date.weekday())
                if week_start not in all_dates:
                    all_dates.append(week_start)
                current_date += td(days=7)
            else:
                # Monthly
                month_start = current_date.replace(day=1)
                if month_start not in all_dates:
                    all_dates.append(month_start)
                # Move to next month
                if current_date.month == 12:
                    current_date = current_date.replace(year=current_date.year + 1, month=1, day=1)
                else:
                    current_date = current_date.replace(month=current_date.month + 1, day=1)
        
        # Convert all dates to string labels for JSON serialization
        if granularity == 'daily':
            labels = [d.strftime('%Y-%m-%d') if isinstance(d, date) else str(d) for d in sorted(set(all_dates))]
        else:
            labels = [str(d) for d in sorted(set(all_dates))]
        
        # Build series with data for all dates (fill missing dates with 0)
        branches = {b.id: b.name for b in Branch.query.all()}
        all_branch_ids = set()
        for period, bid, amt in rows:
            all_branch_ids.add(int(bid))
        
        # If branch_id filter is set, only include that branch
        if branch_id:
            all_branch_ids = {branch_id}
        
        series = {}
        for bid in all_branch_ids:
            series[bid] = []
            for label in labels:
                # Get value for this branch and period, default to 0
                branch_data = out.get(label, {})
                series[bid].append(branch_data.get(bid, 0.0))
        
        # Debug logging
        print(f"DEBUG: Sales trend query for days={days}, branch_id={branch_id}, product_id={product_id}")
        print(f"DEBUG: Date range: {start} to {end} (today in PH time)")
        print(f"DEBUG: Found {len(rows)} total rows")
        print(f"DEBUG: Labels count: {len(labels)} (includes all dates from {start} to {end})")
        print(f"DEBUG: Series keys: {list(series.keys())}")
        for bid in series.keys():
            print(f"DEBUG: Branch {bid} ({branches.get(bid)}): {len(series.get(bid, []))} data points")
        
        return jsonify({"ok": True, "labels": labels, "series": [{"branch_id": bid, "branch_name": branches.get(bid), "data": series.get(bid, [])} for bid in series.keys()]})
    except Exception as e:
        import traceback
        print(f"ERROR in api_sales_trend: {str(e)}")
        print(traceback.format_exc())
        return jsonify({"ok": False, "error": str(e)}), 500

@admin_bp.get("/api/sales/top_products")
def api_sales_top_products():
    from sqlalchemy import func, and_
    from models import Product, InventoryItem
    days = request.args.get('days', type=int)
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    to = request.args.get('to')
    frm = request.args.get('from')
    
    end = datetime.utcnow()
    if to:
        try: 
            # Parse the date and set to end of day (23:59:59.999999) to include the full day
            end_date = datetime.strptime(to, '%Y-%m-%d')
            end = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)
        except: pass
    start = end - timedelta(days=days or 30)
    if frm:
        try: 
            # Parse the date and set to start of day (00:00:00) to include the full day
            start_date = datetime.strptime(frm, '%Y-%m-%d')
            start = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
        except: pass
    # Total sold and sales revenue - start from SalesTransaction and join Product
    q = db.session.query(
        Product.id,
        Product.name,
        func.sum(SalesTransaction.quantity_sold).label('qty'),
        func.sum(SalesTransaction.total_amount).label('amt')
    ).select_from(SalesTransaction).join(Product, Product.id == SalesTransaction.product_id)
    q = q.filter(and_(SalesTransaction.transaction_date >= start, SalesTransaction.transaction_date <= end))
    if branch_id: q = q.filter(SalesTransaction.branch_id == branch_id)
    if product_id: q = q.filter(SalesTransaction.product_id == product_id)
    q = q.group_by(Product.id, Product.name).order_by(func.sum(SalesTransaction.quantity_sold).desc()).limit(10)
    rows = q.all()

    # Current inventory per product (end-of-period), branch-filtered
    inv_q = db.session.query(
        InventoryItem.product_id,
        func.coalesce(func.sum(InventoryItem.stock_kg), 0.0).label('stock')
    )
    if branch_id:
        inv_q = inv_q.filter(InventoryItem.branch_id == branch_id)
    inv_q = inv_q.group_by(InventoryItem.product_id)
    inv_map = {pid: float(stock or 0) for pid, stock in inv_q.all()}

    result = []
    for pid, name, qty, amt in rows:
        end_stock = inv_map.get(pid, 0.0)
        before_kg = float(qty or 0) + end_stock  # approximate: stock before sales in the window
        result.append({
            "name": name,
            "quantity": float(qty or 0),
            "sales": float(amt or 0),
            "before": before_kg,
            "after": end_stock
        })

    return jsonify({"ok": True, "rows": result})

@admin_bp.get("/api/sales/export")
def api_sales_export():
    """Stream CSV or PDF and log to export_logs."""
    import csv, io
    from datetime import datetime
    
    fmt = request.args.get('format', 'csv').lower()
    
    # Get date range for filename
    days = request.args.get('days')
    from_date = request.args.get('from')
    to_date = request.args.get('to')
    
    # Generate filename with date
    date_str = ''
    if from_date and to_date:
        try:
            from_dt = datetime.strptime(from_date, '%Y-%m-%d')
            to_dt = datetime.strptime(to_date, '%Y-%m-%d')
            date_str = f"_{from_dt.strftime('%Y%m%d')}_{to_dt.strftime('%Y%m%d')}"
        except:
            date_str = f"_{datetime.now().strftime('%Y%m%d')}"
    elif days:
        date_str = f"_{datetime.now().strftime('%Y%m%d')}"
    else:
        date_str = f"_{datetime.now().strftime('%Y%m%d')}"
    
    try:
        resp_json = api_sales_list().json
    except Exception:
        # fallback build via direct query
        resp_json = jsonify({"ok": False}).json
    rows = resp_json.get('rows', [])
    
    if fmt == 'pdf':
        # Generate PDF using HTML
        from flask import render_template_string
        # Compute totals
        try:
            total_qty = sum(float(r.get('qty', 0) or 0) for r in rows)
            total_amt = sum(float(r.get('amount', 0) or 0) for r in rows)
        except Exception:
            total_qty = sum([r.get('qty', 0) or 0 for r in rows])
            total_amt = sum([r.get('amount', 0) or 0 for r in rows])
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>Sales Report</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                h1 {{ color: #2e7d32; }}
                table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
                th {{ background-color: #2e7d32; color: white; padding: 10px; text-align: left; }}
                td {{ padding: 8px; border-bottom: 1px solid #ddd; }}
                tr:nth-child(even) {{ background-color: #f2f2f2; }}
                tfoot td {{ border-top: 2px solid #2e7d32; font-weight: bold; background-color: #f5f5f5; }}
                .right {{ text-align: right; }}
            </style>
        </head>
        <body>
            <h1>Sales Report</h1>
            <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <table>
                <thead>
                    <tr>
                        <th>Date</th>
                        <th>Branch</th>
                        <th>Product</th>
                        <th>Qty</th>
                        <th>Amount</th>
                    </tr>
                </thead>
                <tbody>
        """
        for r in rows:
            html_content += f"""
                    <tr>
                        <td>{r.get('date', '')}</td>
                        <td>{r.get('branch_name', '')}</td>
                        <td>{r.get('product_name', '')}</td>
                        <td>{r.get('qty', 0)}</td>
                        <td>â‚±{r.get('amount', 0):,.2f}</td>
                    </tr>
            """
        html_content += f"""
                </tbody>
                <tfoot>
                    <tr>
                        <td colspan="3" class="right">TOTAL</td>
                        <td>{total_qty:,.0f}</td>
                        <td>â‚±{total_amt:,.2f}</td>
                    </tr>
                </tfoot>
            </table>
        </body>
        </html>
        """
        
        # Try to use weasyprint or pdfkit if available, otherwise return HTML
        try:
            import weasyprint
            pdf_data = weasyprint.HTML(string=html_content).write_pdf()
            resp = make_response(pdf_data)
            resp.headers['Content-Type'] = 'application/pdf'
            resp.headers['Content-Disposition'] = f'attachment; filename=sales_export{date_str}.pdf'
        except ImportError:
            try:
                import pdfkit
                pdf_data = pdfkit.from_string(html_content, False)
                resp = make_response(pdf_data)
                resp.headers['Content-Type'] = 'application/pdf'
                resp.headers['Content-Disposition'] = f'attachment; filename=sales_export{date_str}.pdf'
            except ImportError:
                # Fallback to HTML if no PDF library available
                resp = make_response(html_content)
                resp.headers['Content-Type'] = 'text/html'
                resp.headers['Content-Disposition'] = f'attachment; filename=sales_export{date_str}.html'
    else:
        # CSV export
        output = io.StringIO()
        writer = csv.writer(output)
        writer.writerow(['Date','Branch','Product','Qty','Amount'])
        
        # Calculate totals
        total_qty = 0
        total_amt = 0
        
        for r in rows:
            # Format date properly for Excel - use multiple format attempts
            date_str_val = r.get('date', '')
            formatted_date = ''
            
            if date_str_val:
                try:
                    # Try parsing as YYYY-MM-DD first (most common format from API)
                    if isinstance(date_str_val, str) and len(date_str_val) >= 10:
                        # Try YYYY-MM-DD format
                        try:
                            date_obj = datetime.strptime(date_str_val[:10], '%Y-%m-%d')
                            # Format as MM/DD/YYYY for Excel (Excel recognizes this format)
                            formatted_date = date_obj.strftime('%m/%d/%Y')
                        except ValueError:
                            # Try other common formats
                            try:
                                date_obj = datetime.strptime(date_str_val[:10], '%m/%d/%Y')
                                formatted_date = date_obj.strftime('%m/%d/%Y')
                            except ValueError:
                                # If all parsing fails, try to extract date parts manually
                                parts = date_str_val.split('-')
                                if len(parts) >= 3:
                                    # Assume YYYY-MM-DD format
                                    formatted_date = f"{parts[1]}/{parts[2]}/{parts[0]}"
                                else:
                                    formatted_date = date_str_val
                    else:
                        formatted_date = str(date_str_val)
                except Exception as e:
                    # If all parsing fails, use original value
                    formatted_date = str(date_str_val) if date_str_val else ''
            
            qty = float(r.get('qty', 0) or 0)
            amt = float(r.get('amount', 0) or 0)
            total_qty += qty
            total_amt += amt
            
            writer.writerow([
                formatted_date,
                r.get('branch_name', ''),
                r.get('product_name', ''),
                qty,
                amt
            ])
        
        # Add totals row
        writer.writerow([])  # Empty row for spacing
        writer.writerow(['TOTAL', '', '', total_qty, total_amt])
        
        data = output.getvalue()
        resp = make_response(data)
        resp.headers['Content-Type'] = 'text/csv'
        resp.headers['Content-Disposition'] = f'attachment; filename=sales_export{date_str}.csv'

    # log export
    try:
        log = ExportLog(
            user_id=(session.get('user') or {}).get('id'),
            report_type='sales',
            filters_json=json.dumps({k:v for k,v in request.args.items()}),
            file_type=fmt,
            status='completed'
        )
        db.session.add(log)
        db.session.commit()
    except Exception:
        db.session.rollback()

    return resp

@admin_bp.get("/api/sales/transactions")
def api_get_sales_transactions():
    """Get sales transactions with optional filtering"""
    from models import SalesTransaction
    from datetime import datetime, timedelta
    
    # Get query parameters
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    days = request.args.get('days', 30, type=int)
    
    # Build query
    query = SalesTransaction.query
    
    if branch_id:
        query = query.filter_by(branch_id=branch_id)
    if product_id:
        query = query.filter_by(product_id=product_id)
    
    # Filter by date range
    start_date = datetime.now() - timedelta(days=days)
    query = query.filter(SalesTransaction.transaction_date >= start_date)
    
    transactions = query.order_by(SalesTransaction.transaction_date.desc()).all()
    
    return jsonify({
        "ok": True,
        "transactions": [t.to_dict() for t in transactions],
        "total": len(transactions)
    })

# ========== REPORTS API ENDPOINTS ==========

def _paginate(query, page, page_size):
    total = query.count()
    pages = (total + page_size - 1) // page_size if page_size > 0 else 1
    rows = query.offset((page - 1) * page_size).limit(page_size).all() if page_size > 0 else query.all()
    return rows, {"page": page, "pages": pages, "count": total}

def _parse_date(s, default):
    from datetime import datetime
    if not s:
        return default
    try:
        return datetime.strptime(s, "%Y-%m-%d")
    except Exception:
        return default

@admin_bp.get("/api/reports/sales")
def api_reports_sales():
    from sqlalchemy import func
    from datetime import datetime, timedelta
    # Params
    from_str = request.args.get('from')
    to_str = request.args.get('to')
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    granularity = request.args.get('granularity', 'day')  # day|week|month
    page = request.args.get('page', 1, type=int)
    page_size = request.args.get('page_size', 50, type=int)

    now = datetime.now()
    start = _parse_date(from_str, now - timedelta(days=30))
    end = _parse_date(to_str, now)

    # Base query
    q = db.session.query(
        func.date(SalesTransaction.transaction_date).label('d'),
        SalesTransaction.branch_id,
        SalesTransaction.product_id,
        func.sum(SalesTransaction.quantity_sold).label('qty'),
        func.sum(SalesTransaction.total_amount).label('amt')
    ).filter(SalesTransaction.transaction_date >= start,
             SalesTransaction.transaction_date <= end)
    if branch_id:
        q = q.filter(SalesTransaction.branch_id == branch_id)
    if product_id:
        q = q.filter(SalesTransaction.product_id == product_id)

    # Grouping by granularity
    if granularity == 'month':
        q = q.with_entities(
            func.to_char(SalesTransaction.transaction_date, 'YYYY-MM').label('period'),
            SalesTransaction.branch_id,
            SalesTransaction.product_id,
            func.sum(SalesTransaction.quantity_sold).label('qty'),
            func.sum(SalesTransaction.total_amount).label('amt')
        ).group_by('period', SalesTransaction.branch_id, SalesTransaction.product_id)
    elif granularity == 'week':
        q = q.with_entities(
            func.to_char(SalesTransaction.transaction_date, 'IYYY-IW').label('period'),
            SalesTransaction.branch_id,
            SalesTransaction.product_id,
            func.sum(SalesTransaction.quantity_sold).label('qty'),
            func.sum(SalesTransaction.total_amount).label('amt')
        ).group_by('period', SalesTransaction.branch_id, SalesTransaction.product_id)
    else:
        q = q.group_by('d', SalesTransaction.branch_id, SalesTransaction.product_id)

    q = q.order_by('period' if granularity in ('week', 'month') else 'd')
    rows, meta = _paginate(q, page, page_size)

    # Map IDs to names
    branch_map = {b.id: b.name for b in Branch.query.all()}
    product_map = {p.id: p.name for p in Product.query.all()}

    out_rows = []
    sum_qty, sum_amt = 0.0, 0.0
    for r in rows:
        if granularity in ('week', 'month'):
            period = r[0]
            bid, pid, qty, amt = r[1], r[2], float(r[3] or 0), float(r[4] or 0)
            date_label = period
        else:
            d, bid, pid, qty, amt = r[0], r[1], r[2], float(r[3] or 0), float(r[4] or 0)
            date_label = d.strftime('%Y-%m-%d')
        sum_qty += qty
        sum_amt += amt
        out_rows.append({
            "date": date_label,
            "branch_id": bid,
            "branch_name": branch_map.get(bid),
            "product_id": pid,
            "product_name": product_map.get(pid),
            "qty_kg": qty,
            "amount": amt,
        })

    return jsonify({
        "ok": True,
        "rows": out_rows,
        "totals": {"sum_qty_kg": sum_qty, "sum_amount": sum_amt},
        "meta": meta,
    })

@admin_bp.get("/api/reports/forecast")
def api_reports_forecast():
    from sqlalchemy import func, and_
    from datetime import datetime, timedelta
    from_str = request.args.get('from')
    to_str = request.args.get('to')
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    model_type = request.args.get('model_type')  # optional filter
    page = request.args.get('page', 1, type=int)
    page_size = request.args.get('page_size', 50, type=int)

    now = datetime.now().date()
    start = _parse_date(from_str, datetime.combine(now - timedelta(days=30), datetime.min.time())).date()
    end = _parse_date(to_str, datetime.combine(now, datetime.min.time())).date()

    q = db.session.query(
        ForecastData.forecast_date,
        ForecastData.branch_id,
        ForecastData.product_id,
        func.sum(ForecastData.predicted_demand).label('forecast_kg')
    ).filter(and_(ForecastData.forecast_date >= start, ForecastData.forecast_date <= end))
    if branch_id:
        q = q.filter(ForecastData.branch_id == branch_id)
    if product_id:
        q = q.filter(ForecastData.product_id == product_id)
    if model_type:
        q = q.filter(ForecastData.model_type.ilike(model_type))

    q = q.group_by(ForecastData.forecast_date, ForecastData.branch_id, ForecastData.product_id)
    q = q.order_by(ForecastData.forecast_date)
    rows, meta = _paginate(q, page, page_size)

    # Compute actual and errors per row
    branch_map = {b.id: b.name for b in Branch.query.all()}
    product_map = {p.id: p.name for p in Product.query.all()}
    out_rows = []
    sum_forecast, sum_actual, mape_sum, mape_count = 0.0, 0.0, 0.0, 0
    for d, bid, pid, fkg in rows:
        actual = db.session.query(func.sum(SalesTransaction.quantity_sold)).filter(
            and_(SalesTransaction.branch_id == bid,
                 SalesTransaction.product_id == pid,
                 func.date(SalesTransaction.transaction_date) == d)
        ).scalar() or 0
        fkg = float(fkg or 0)
        akg = float(actual or 0)
        diff = fkg - akg
        ape = abs(diff) / akg * 100 if akg > 0 else None
        if ape is not None:
            mape_sum += ape
            mape_count += 1
        sum_forecast += fkg
        sum_actual += akg
        out_rows.append({
            "date": d.strftime('%Y-%m-%d'),
            "branch_id": bid,
            "branch_name": branch_map.get(bid),
            "product_id": pid,
            "product_name": product_map.get(pid),
            "forecast_kg": fkg,
            "actual_kg": akg,
            "diff_kg": round(diff, 2),
            "abs_pct_err": round(ape, 2) if ape is not None else None,
        })

    mape = (mape_sum / mape_count) if mape_count > 0 else None
    return jsonify({
        "ok": True,
        "rows": out_rows,
        "totals": {"sum_forecast_kg": sum_forecast, "sum_actual_kg": sum_actual, "mape": round(mape, 2) if mape is not None else None},
        "meta": meta,
    })

# ========== REGIONAL INSIGHTS API ENDPOINTS ==========

@admin_bp.get("/api/regional/stock")
@admin_required
def api_regional_stock():
    """Get stock levels by branch for regional insights"""
    from sqlalchemy import func
    
    product = request.args.get('product')
    category = request.args.get('category')
    branch = request.args.get('branch')
    
    # Base query for inventory items
    q = db.session.query(
        Branch.name.label('branch_name'),
        func.sum(InventoryItem.stock_kg).label('total_stock'),
        func.count(InventoryItem.id).label('product_count')
    ).join(InventoryItem, Branch.id == InventoryItem.branch_id)
    
    # Apply filters
    if branch and branch != 'all':
        q = q.filter(Branch.name.ilike(f'%{branch}%'))
    
    if product and product != 'all':
        q = q.join(Product, InventoryItem.product_id == Product.id)
        q = q.filter(Product.name.ilike(f'%{product}%'))
    
    if category and category != 'all':
        q = q.join(Product, InventoryItem.product_id == Product.id)
        q = q.filter(Product.category.ilike(f'%{category}%'))
    
    # Group by branch
    results = q.group_by(Branch.id, Branch.name).all()
    
    # Format response
    branches = []
    total_stock = 0
    
    for result in results:
        stock_kg = float(result.total_stock or 0)
        total_stock += stock_kg
        
        branches.append({
            'branch_name': str(result.branch_name),  # Convert to string to avoid Row object issues
            'stock_kg': stock_kg,
            'product_count': int(result.product_count or 0)
        })
    
    # If no stock data exists, generate sample data based on real branches
    if not branches:
        print("DEBUG: No stock data found, generating sample data based on real branches")
        # Get all branches from database
        all_branches = Branch.query.all()
        
        for branch_obj in all_branches:
            # Generate realistic stock data
            stock_kg = 2000 + (hash(branch_obj.name) % 3000)  # 2000-5000 kg
            product_count = 3 + (hash(branch_obj.name) % 5)  # 3-8 products
            
            branches.append({
                'branch_name': branch_obj.name,
                'stock_kg': float(stock_kg),
                'product_count': product_count
            })
            total_stock += stock_kg
    
    print(f"DEBUG: Regional Stock API - Found {len(branches)} branches, total stock: {total_stock}")
    
    return jsonify({
        "ok": True,
        "branches": branches,
        "total_stock": total_stock,
        "filters": {
            "product": product,
            "category": category,
            "branch": branch
        }
    })

@admin_bp.get("/api/regional/sales")
@admin_required
def api_regional_sales():
    """Get sales performance by branch for regional insights - based on REAL SalesTransaction data"""
    from sqlalchemy import func, and_
    from datetime import datetime, timedelta
    
    product = request.args.get('product')
    category = request.args.get('category')
    branch = request.args.get('branch')
    from_date = request.args.get('from')
    to_date = request.args.get('to')
    
    # Default to last 6 months if no dates provided
    if not from_date:
        from_date = (datetime.now() - timedelta(days=180)).strftime('%Y-%m-%d')
    if not to_date:
        to_date = datetime.now().strftime('%Y-%m-%d')
    
    try:
        start_date = datetime.strptime(from_date, '%Y-%m-%d')
        end_date = datetime.strptime(to_date, '%Y-%m-%d')
    except:
        start_date = datetime.now() - timedelta(days=180)
        end_date = datetime.now()
    
    # Query REAL sales data from SalesTransaction table
    q = db.session.query(
        func.to_char(SalesTransaction.transaction_date, 'YYYY-MM').label('month'),
        Branch.name.label('branch_name'),
        func.sum(SalesTransaction.total_amount).label('sales_amount'),
        func.sum(SalesTransaction.quantity_sold).label('sales_kg')
    ).join(Branch, SalesTransaction.branch_id == Branch.id)
    
    # Apply date filter
    q = q.filter(
        and_(
            SalesTransaction.transaction_date >= start_date,
            SalesTransaction.transaction_date <= end_date
        )
    )
    
    # Apply filters
    if branch and branch != 'all':
        q = q.filter(Branch.name.ilike(f'%{branch}%'))
    
    if product and product != 'all':
        q = q.join(Product, SalesTransaction.product_id == Product.id)
        q = q.filter(Product.name.ilike(f'%{product}%'))
    
    if category and category != 'all':
        q = q.join(Product, SalesTransaction.product_id == Product.id)
        q = q.filter(Product.category.ilike(f'%{category}%'))
    
    # Group by month and branch
    results = q.group_by(
        func.to_char(SalesTransaction.transaction_date, 'YYYY-MM'),
        Branch.id, Branch.name
    ).order_by('month').all()
    
    # Build response data
    months_set = set()
    branch_data = {}
    
    for result in results:
        month = str(result.month)
        branch_name = str(result.branch_name)
        sales_amount = float(result.sales_amount or 0)
        sales_kg = float(result.sales_kg or 0)
        
        months_set.add(month)
        
        if branch_name not in branch_data:
            branch_data[branch_name] = []
        
        branch_data[branch_name].append({
            'month': month,
            'sales_amount': sales_amount,
            'sales_kg': sales_kg
        })
    
    # Sort months chronologically
    months = sorted(list(months_set))
    
    # Ensure all branches have data for all months (fill missing months with 0)
    all_branches = Branch.query.all()
    for branch_obj in all_branches:
        branch_name = branch_obj.name
        if branch_name not in branch_data:
            branch_data[branch_name] = []
        
        # Fill missing months with 0
        existing_months = {item['month'] for item in branch_data[branch_name]}
        for month in months:
            if month not in existing_months:
                branch_data[branch_name].append({
                    'month': month,
                    'sales_amount': 0.0,
                    'sales_kg': 0.0
                })
        
        # Sort by month
        branch_data[branch_name].sort(key=lambda x: x['month'])
    
    # If no data exists, return empty structure (don't generate fake data)
    if not months:
        # Generate month labels for last 6 months
        current_date = datetime.now()
        months = []
        for i in range(6):
            month_date = current_date - timedelta(days=30*(5-i))
            months.append(month_date.strftime('%Y-%m'))
        
        # Initialize empty data for all branches
        for branch_obj in all_branches:
            branch_data[branch_obj.name] = [
                {'month': month, 'sales_amount': 0.0, 'sales_kg': 0.0}
                for month in months
            ]
    
    print(f"DEBUG: Regional Sales API - Date range: {from_date} to {to_date}")
    print(f"DEBUG: Found {len(months)} months with REAL data: {months}")
    print(f"DEBUG: Branch data keys: {list(branch_data.keys())}")
    for branch_name, data in branch_data.items():
        total_sales = sum(item['sales_amount'] for item in data)
        print(f"DEBUG: {branch_name} - Total sales: â‚±{total_sales:,.2f}")
    
    return jsonify({
        "ok": True,
        "months": months,
        "branch_data": branch_data,
        "filters": {
            "product": product,
            "category": category,
            "branch": branch,
            "from_date": from_date,
            "to_date": to_date
        }
    })

@admin_bp.get("/api/regional/forecast")
@admin_required
def api_regional_forecast():
    """Get regional forecasting data"""
    from sqlalchemy import func, and_
    from datetime import datetime, timedelta
    
    product = request.args.get('product')
    category = request.args.get('category')
    branch = request.args.get('branch')
    
    # Base query for forecast data
    q = db.session.query(
        func.to_char(ForecastData.forecast_date, 'YYYY-MM').label('month'),
        Branch.name.label('branch_name'),
        func.avg(ForecastData.predicted_demand).label('avg_demand'),
        func.avg(ForecastData.accuracy_score).label('avg_accuracy')
    ).join(Branch, ForecastData.branch_id == Branch.id)
    
    # Apply filters
    if branch and branch != 'all':
        q = q.filter(Branch.name.ilike(f'%{branch}%'))
    
    if product and product != 'all':
        q = q.join(Product, ForecastData.product_id == Product.id)
        q = q.filter(Product.name.ilike(f'%{product}%'))
    
    if category and category != 'all':
        q = q.join(Product, ForecastData.product_id == Product.id)
        q = q.filter(Product.category.ilike(f'%{category}%'))
    
    # Group by month and branch
    results = q.group_by(
        func.to_char(ForecastData.forecast_date, 'YYYY-MM'),
        Branch.id, Branch.name
    ).order_by('month').all()
    
    # Format response
    months = []
    branch_forecasts = {}
    
    for result in results:
        month = str(result.month)  # Convert to string to avoid Row object issues
        if month not in months:
            months.append(month)
        
        branch_name = str(result.branch_name)  # Convert to string to avoid Row object issues
        if branch_name not in branch_forecasts:
            branch_forecasts[branch_name] = []
        
        branch_forecasts[branch_name].append({
            'month': month,
            'avg_demand': float(result.avg_demand or 0),
            'avg_accuracy': float(result.avg_accuracy or 0)
        })
    
    # If no forecast data exists, generate sample data based on real branches
    if not months:
        print("DEBUG: No forecast data found, generating sample data based on real branches")
        # Get all branches from database
        all_branches = Branch.query.all()
        current_date = datetime.now()
        months = []
        
        # Generate last 4 months
        for i in range(4):
            month_date = current_date + timedelta(days=30*i)
            month_str = month_date.strftime('%Y-%m')
            months.append(month_str)
        
        # Generate sample forecast data for each branch
        for branch_obj in all_branches:
            branch_name = branch_obj.name
            branch_forecasts[branch_name] = []
            
            for month in months:
                # Generate realistic forecast data
                base_demand = 50 + (hash(branch_name) % 30)  # Vary by branch (50-80 kg)
                month_variation = (hash(month) % 20) - 10  # Vary by month
                sample_demand = max(20, base_demand + month_variation)
                sample_accuracy = 75 + (hash(branch_name + month) % 20)  # 75-95% accuracy
                
                branch_forecasts[branch_name].append({
                    'month': month,
                    'avg_demand': float(sample_demand),
                    'avg_accuracy': float(sample_accuracy)
                })
    
    # Ensure all branches have forecast data (fill missing branches with sample data)
    all_branches = Branch.query.all()
    all_branch_names = [branch.name for branch in all_branches]
    missing_branches = [name for name in all_branch_names if name not in branch_forecasts]
    
    if missing_branches:
        print(f"DEBUG: Missing forecast data for branches: {missing_branches}, generating sample data")
        current_date = datetime.now()
        
        # Ensure we have months for sample data
        if not months:
            months = []
            for i in range(4):
                month_date = current_date + timedelta(days=30*i)
                month_str = month_date.strftime('%Y-%m')
                months.append(month_str)
        
        # Generate sample forecast data for missing branches
        for branch_name in missing_branches:
            branch_forecasts[branch_name] = []
            
            for month in months:
                # Generate realistic forecast data
                base_demand = 50 + (hash(branch_name) % 30)  # Vary by branch (50-80 kg)
                month_variation = (hash(month) % 20) - 10  # Vary by month
                sample_demand = max(20, base_demand + month_variation)
                sample_accuracy = 75 + (hash(branch_name + month) % 20)  # 75-95% accuracy
                
                branch_forecasts[branch_name].append({
                    'month': month,
                    'avg_demand': float(sample_demand),
                    'avg_accuracy': float(sample_accuracy)
                })
    
    print(f"DEBUG: Regional Forecast API - Found {len(months)} months: {months}")
    print(f"DEBUG: Branch forecasts keys: {list(branch_forecasts.keys())}")
    
    return jsonify({
        "ok": True,
        "months": months,
        "branch_forecasts": branch_forecasts,
        "filters": {
            "product": product,
            "category": category,
            "branch": branch
        }
    })

@admin_bp.get("/api/regional/gaps")
@admin_required
def api_regional_gaps():
    """Get demand-supply gaps by branch"""
    from sqlalchemy import func, and_
    from datetime import date, timedelta
    
    product = request.args.get('product')
    category = request.args.get('category')
    branch = request.args.get('branch')
    
    # Get today's date for forecast filtering (use Philippines timezone if available)
    today = date.today()
    next_30_days = today + timedelta(days=30)
    
    # Query for inventory stock levels
    stock_q = db.session.query(
        Branch.id.label('branch_id'),
        Branch.name.label('branch_name'),
        Product.id.label('product_id'),
        Product.name.label('product_name'),
        func.sum(InventoryItem.stock_kg).label('current_stock')
    ).join(InventoryItem, Branch.id == InventoryItem.branch_id)\
     .join(Product, InventoryItem.product_id == Product.id)
    
    # Apply filters
    if branch and branch != 'all':
        stock_q = stock_q.filter(Branch.name.ilike(f'%{branch}%'))
    
    if product and product != 'all':
        stock_q = stock_q.filter(Product.name.ilike(f'%{product}%'))
    
    if category and category != 'all':
        stock_q = stock_q.filter(Product.category.ilike(f'%{category}%'))
    
    # Group by branch and product
    stock_results = stock_q.group_by(Branch.id, Branch.name, Product.id, Product.name).all()
    
    # Get forecasted demand for next 30 days (sum of upcoming forecasts)
    forecast_q = db.session.query(
        ForecastData.branch_id,
        ForecastData.product_id,
        func.sum(ForecastData.predicted_demand).label('forecast_demand')
    ).filter(
        and_(
            ForecastData.forecast_date >= today,
            ForecastData.forecast_date <= next_30_days
        )
    ).group_by(ForecastData.branch_id, ForecastData.product_id)
    
    # Create a map of (branch_id, product_id) -> forecast_demand
    forecast_map = {}
    for fid, pid, fdemand in forecast_q.all():
        forecast_map[(fid, pid)] = float(fdemand or 0)
    
    # Calculate gaps
    gaps = []
    for result in stock_results:
        branch_id = result.branch_id
        product_id = result.product_id
        current_stock = float(result.current_stock or 0)
        
        # Get forecasted demand for next 30 days, or use 0 if no forecast exists
        forecast_demand = forecast_map.get((branch_id, product_id), 0.0)
        
        # If no forecast exists, calculate based on average daily sales from last 30 days
        if forecast_demand == 0:
            # Try to get average daily sales for this product/branch
            from datetime import datetime, timedelta
            thirty_days_ago = datetime.now() - timedelta(days=30)
            avg_sales = db.session.query(
                func.avg(SalesTransaction.quantity_sold).label('avg_daily')
            ).filter(
                and_(
                    SalesTransaction.branch_id == branch_id,
                    SalesTransaction.product_id == product_id,
                    SalesTransaction.transaction_date >= thirty_days_ago
                )
            ).scalar()
            
            # Estimate 30-day demand based on average daily sales
            if avg_sales:
                forecast_demand = float(avg_sales) * 30
            else:
                # No sales data, use a conservative estimate
                forecast_demand = current_stock * 0.5  # Assume 50% of current stock as demand
        
        gap = current_stock - forecast_demand
        
        # Calculate gap percentage for better classification
        gap_percentage = (gap / forecast_demand * 100) if forecast_demand > 0 else 0
        
        # Classify gap status
        # Requirement: Any shortage should be shown as RED (critical).
        # Surplus remains orange (warning). Balanced stays blue (info).
        if gap < 0:  # Any shortage
            status = 'critical'
            gap_text = f'Shortage: {abs(gap):.0f}kg'
        elif gap > forecast_demand * 0.2:  # Surplus more than 20% of demand
            status = 'warning'
            gap_text = f'Surplus: {gap:.0f}kg'
        else:  # Balanced (within Â±20% of demand)
            status = 'info'
            gap_text = 'Balanced'
        
        gaps.append({
            'branch_name': str(result.branch_name),
            'product_name': str(result.product_name),
            'current_stock': round(current_stock, 2),
            'forecast_demand': round(forecast_demand, 2),
            'gap': round(gap, 2),
            'status': status,
            'gap_text': gap_text
        })
    
    # If no gaps data exists, it means there are no inventory items matching the filters
    # This is expected behavior - only show gaps for products that exist in inventory
    if not gaps:
        print(f"DEBUG: No inventory items found for filters - product: {product}, branch: {branch}")
        # Don't generate fake data - return empty list
        # This is more accurate than showing misleading sample data
    
    # Sort by gap severity (shortages first, then by gap amount)
    gaps.sort(key=lambda x: (x['gap'] < 0, abs(x['gap'])), reverse=True)
    
    print(f"DEBUG: Regional Gaps API - Found {len(gaps)} gaps")
    if gaps:
        print(f"DEBUG: Sample gap - Branch: {gaps[0]['branch_name']}, Product: {gaps[0]['product_name']}, Stock: {gaps[0]['current_stock']}, Forecast: {gaps[0]['forecast_demand']}, Gap: {gaps[0]['gap']}")
    
    return jsonify({
        "ok": True,
        "gaps": gaps,
        "filters": {
            "product": product,
            "category": category,
            "branch": branch
        }
    })

@admin_bp.get("/api/regional/export")
@admin_required
def api_regional_export():
    """Export regional insights data as CSV"""
    from flask import make_response
    import csv
    import io
    from sqlalchemy import func, and_
    from datetime import date, timedelta
    
    # Get current filters
    product = request.args.get('product', 'all')
    category = request.args.get('category', 'all')
    branch = request.args.get('branch', 'all')
    
    # Create CSV content
    output = io.StringIO()
    writer = csv.writer(output)
    
    # Write headers
    writer.writerow(['Regional Insights Export'])
    writer.writerow([f'Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'])
    writer.writerow([f'Filters: Product={product}, Category={category}, Branch={branch}'])
    writer.writerow([])
    
    # Get stock data directly
    try:
        stock_q = db.session.query(
            Branch.name.label('branch_name'),
            func.sum(InventoryItem.stock_kg).label('stock_kg'),
            func.count(func.distinct(InventoryItem.product_id)).label('product_count')
        ).join(InventoryItem, Branch.id == InventoryItem.branch_id)
        
        if branch and branch != 'all':
            stock_q = stock_q.filter(Branch.name.ilike(f'%{branch}%'))
        
        if product and product != 'all':
            stock_q = stock_q.join(Product, InventoryItem.product_id == Product.id)
            stock_q = stock_q.filter(Product.name.ilike(f'%{product}%'))
        
        if category and category != 'all':
            stock_q = stock_q.join(Product, InventoryItem.product_id == Product.id)
            stock_q = stock_q.filter(Product.category.ilike(f'%{category}%'))
        
        stock_results = stock_q.group_by(Branch.id, Branch.name).all()
        
        writer.writerow(['Branch Stock Levels'])
        writer.writerow(['Branch', 'Stock (kg)', 'Product Count'])
        for result in stock_results:
            writer.writerow([
                result.branch_name,
                float(result.stock_kg or 0),
                int(result.product_count or 0)
            ])
        writer.writerow([])
    except Exception as e:
        print(f"Error exporting stock data: {e}")
        writer.writerow(['Branch Stock Levels - Error loading data'])
        writer.writerow([])
    
    # Get gaps data directly
    try:
        today = date.today()
        next_30_days = today + timedelta(days=30)
        
        stock_q = db.session.query(
            Branch.id.label('branch_id'),
            Branch.name.label('branch_name'),
            Product.id.label('product_id'),
            Product.name.label('product_name'),
            func.sum(InventoryItem.stock_kg).label('current_stock')
        ).join(InventoryItem, Branch.id == InventoryItem.branch_id)\
         .join(Product, InventoryItem.product_id == Product.id)
        
        if branch and branch != 'all':
            stock_q = stock_q.filter(Branch.name.ilike(f'%{branch}%'))
        
        if product and product != 'all':
            stock_q = stock_q.filter(Product.name.ilike(f'%{product}%'))
        
        if category and category != 'all':
            stock_q = stock_q.filter(Product.category.ilike(f'%{category}%'))
        
        stock_results = stock_q.group_by(Branch.id, Branch.name, Product.id, Product.name).all()
        
        # Get forecast data
        forecast_q = db.session.query(
            ForecastData.branch_id,
            ForecastData.product_id,
            func.sum(ForecastData.predicted_demand).label('forecast_demand')
        ).filter(
            and_(
                ForecastData.forecast_date >= today,
                ForecastData.forecast_date <= next_30_days
            )
        )
        
        if branch and branch != 'all':
            forecast_q = forecast_q.join(Branch, ForecastData.branch_id == Branch.id)
            forecast_q = forecast_q.filter(Branch.name.ilike(f'%{branch}%'))
        
        if product and product != 'all':
            forecast_q = forecast_q.join(Product, ForecastData.product_id == Product.id)
            forecast_q = forecast_q.filter(Product.name.ilike(f'%{product}%'))
        
        if category and category != 'all':
            forecast_q = forecast_q.join(Product, ForecastData.product_id == Product.id)
            forecast_q = forecast_q.filter(Product.category.ilike(f'%{category}%'))
        
        forecast_results = forecast_q.group_by(ForecastData.branch_id, ForecastData.product_id).all()
        forecast_map = {(int(r.branch_id), int(r.product_id)): float(r.forecast_demand or 0) for r in forecast_results}
        
        gaps = []
        for stock_result in stock_results:
            try:
                branch_id = int(stock_result.branch_id)
                product_id = int(stock_result.product_id)
                forecast_demand = forecast_map.get((branch_id, product_id), 0.0)
                current_stock = float(stock_result.current_stock or 0)
                gap = current_stock - forecast_demand
                
                # If no forecast data, try to estimate from sales
                if forecast_demand == 0:
                    try:
                        sales_q = db.session.query(
                            func.avg(SalesTransaction.quantity_kg).label('avg_daily_sales')
                        ).filter(
                            SalesTransaction.branch_id == branch_id,
                            SalesTransaction.product_id == product_id
                        )
                        sales_result = sales_q.first()
                        avg_daily_sales = float(sales_result.avg_daily_sales or 0) if sales_result else 0
                        forecast_demand = avg_daily_sales * 30  # Estimate for 30 days
                        gap = current_stock - forecast_demand
                    except Exception as sales_err:
                        # If sales query fails, just use 0 for forecast
                        forecast_demand = 0.0
                        gap = current_stock
                
                # Determine status
                if forecast_demand > 0:
                    if gap < 0:
                        gap_percent = abs(gap / forecast_demand * 100)
                        if gap_percent >= 20:
                            status = 'critical'
                            gap_text = f'Critical shortage: {abs(gap):.2f} kg ({gap_percent:.1f}% below demand)'
                        else:
                            status = 'warning'
                            gap_text = f'Shortage: {abs(gap):.2f} kg ({gap_percent:.1f}% below demand)'
                    elif gap > forecast_demand * 0.2:
                        status = 'warning'
                        gap_text = f'Surplus: {gap:.2f} kg (exceeds demand by {gap/forecast_demand*100:.1f}%)'
                    else:
                        status = 'info'
                        gap_text = f'Balanced: {gap:.2f} kg gap'
                else:
                    # No forecast data available
                    if current_stock > 0:
                        status = 'info'
                        gap_text = f'Stock available: {current_stock:.2f} kg (no forecast data)'
                    else:
                        status = 'warning'
                        gap_text = f'No stock and no forecast data'
                
                gaps.append({
                    'branch_name': str(stock_result.branch_name),
                    'product_name': str(stock_result.product_name),
                    'current_stock': round(current_stock, 2),
                    'forecast_demand': round(forecast_demand, 2),
                    'gap': round(gap, 2),
                    'status': status,
                    'gap_text': gap_text
                })
            except Exception as item_err:
                # Skip this item if there's an error processing it
                print(f"Error processing gap item: {item_err}")
                continue
        
        writer.writerow(['Demand-Supply Gaps (Next 30 Days)'])
        writer.writerow(['Branch', 'Product', 'Current Stock (kg)', 'Forecast Demand (kg)', 'Gap (kg)', 'Status', 'Gap Description'])
        
        if gaps:
            for gap in gaps:
                writer.writerow([
                    gap['branch_name'],
                    gap['product_name'],
                    gap['current_stock'],
                    gap['forecast_demand'],
                    gap['gap'],
                    gap['status'],
                    gap['gap_text']
                ])
        else:
            writer.writerow(['No data available - No inventory items match the selected filters, or no forecast data exists.'])
        
        writer.writerow([])
        writer.writerow(['Note: Forecast Demand is the sum of predicted demand for the next 30 days'])
        writer.writerow(['Gap = Current Stock - Forecast Demand (positive = surplus, negative = shortage)'])
    except Exception as e:
        print(f"Error exporting gaps data: {e}")
        import traceback
        traceback.print_exc()
        writer.writerow(['Demand-Supply Gaps (Next 30 Days)'])
        writer.writerow(['Branch', 'Product', 'Current Stock (kg)', 'Forecast Demand (kg)', 'Gap (kg)', 'Status', 'Gap Description'])
        writer.writerow([f'Error loading data: {str(e)}'])
        writer.writerow([])
    
    # Create response
    output.seek(0)
    response = make_response(output.getvalue())
    response.headers['Content-Type'] = 'text/csv; charset=utf-8'
    response.headers['Content-Disposition'] = f'attachment; filename=regional_insights_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
    
    return response

@admin_bp.get("/api/catalog")
@admin_required
def api_catalog():
    """Get catalog data for filter options"""
    from sqlalchemy import func
    
    # Get unique products
    products = db.session.query(Product.name).distinct().all()
    product_list = [p.name for p in products]
    
    # Get unique categories
    categories = db.session.query(Product.category).distinct().filter(Product.category.isnot(None)).all()
    category_list = [c.category for c in categories]
    
    # Get unique branches
    branches = db.session.query(Branch.name).distinct().all()
    branch_list = [b.name for b in branches]
    
    return jsonify({
        "ok": True,
        "products": product_list,
        "categories": category_list,
        "branches": branch_list
    })

@admin_bp.get("/api/reports/inventory")
def api_reports_inventory():
    from sqlalchemy import func, and_
    from datetime import datetime, timedelta
    from_str = request.args.get('from')
    to_str = request.args.get('to')
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    page = request.args.get('page', 1, type=int)
    page_size = request.args.get('page_size', 50, type=int)

    now = datetime.now().date()
    start = _parse_date(from_str, datetime.combine(now - timedelta(days=30), datetime.min.time())).date()
    end = _parse_date(to_str, datetime.combine(now, datetime.min.time())).date()

    # We approximate inventory daily from logs and sales; for simplicity, we provide received (restock) and sold per day, closing as current stock for now
    # received per day
    recv_q = db.session.query(
        func.date(RestockLog.created_at).label('d'),
        InventoryItem.branch_id,
        InventoryItem.product_id,
        func.sum(RestockLog.qty_kg).label('received_kg')
    ).join(InventoryItem, RestockLog.inventory_item_id == InventoryItem.id)
    if branch_id:
        recv_q = recv_q.filter(InventoryItem.branch_id == branch_id)
    if product_id:
        recv_q = recv_q.filter(InventoryItem.product_id == product_id)
    recv_q = recv_q.filter(func.date(RestockLog.created_at) >= start, func.date(RestockLog.created_at) <= end)
    recv_q = recv_q.group_by('d', InventoryItem.branch_id, InventoryItem.product_id)
    recv_rows = recv_q.all()
    recv_map = {(r.d, r.branch_id, r.product_id): float(r.received_kg or 0) for r in recv_rows}

    # sold per day
    sold_q = db.session.query(
        func.date(SalesTransaction.transaction_date).label('d'),
        SalesTransaction.branch_id,
        SalesTransaction.product_id,
        func.sum(SalesTransaction.quantity_sold).label('sold_kg')
    ).filter(func.date(SalesTransaction.transaction_date) >= start, func.date(SalesTransaction.transaction_date) <= end)
    if branch_id:
        sold_q = sold_q.filter(SalesTransaction.branch_id == branch_id)
    if product_id:
        sold_q = sold_q.filter(SalesTransaction.product_id == product_id)
    sold_q = sold_q.group_by('d', SalesTransaction.branch_id, SalesTransaction.product_id)
    sold_rows = sold_q.all()
    sold_map = {(r.d, r.branch_id, r.product_id): float(r.sold_kg or 0) for r in sold_rows}

    # Closing (current snapshot) per branch/product
    inv_rows = InventoryItem.query.all()
    inv_map = {(it.branch_id, it.product_id): float(it.stock_kg or 0) for it in inv_rows}

    # Build combined rows for dates in range
    branch_map = {b.id: b.name for b in Branch.query.all()}
    product_map = {p.id: p.name for p in Product.query.all()}
    all_keys = set(list(recv_map.keys()) + list(sold_map.keys()))
    rows_list = []
    for (d, bid, pid) in sorted(all_keys):
        rows_list.append({
            "date": d.strftime('%Y-%m-%d'),
            "branch_id": bid,
            "branch_name": branch_map.get(bid),
            "product_id": pid,
            "product_name": product_map.get(pid),
            "opening_kg": None,  # optional; requires back-calculation
            "received_kg": recv_map.get((d, bid, pid), 0.0),
            "sold_kg": sold_map.get((d, bid, pid), 0.0),
            "closing_kg": inv_map.get((bid, pid), 0.0),
        })

    # Pagination
    total_count = len(rows_list)
    pages = (total_count + page_size - 1) // page_size if page_size > 0 else 1
    start_idx = (page - 1) * page_size
    end_idx = start_idx + page_size
    page_rows = rows_list[start_idx:end_idx]

    # Totals (avg closing)
    avg_closing = sum(r["closing_kg"] for r in rows_list) / total_count if total_count > 0 else 0

    return jsonify({
        "ok": True,
        "rows": page_rows,
        "totals": {"avg_closing_kg": round(avg_closing, 2)},
        "meta": {"page": page, "pages": pages, "count": total_count}
    })

@admin_bp.get("/api/reports/forecast")
def api_generate_forecast_report():
    """Generate forecast report"""
    from models import ForecastData
    from reports_service import reports_service
    from datetime import datetime, timedelta
    
    # Get recent forecasts
    end_date = datetime.now().date() + timedelta(days=30)
    forecasts = (
        ForecastData.query
        .filter(ForecastData.forecast_date >= datetime.now().date())
        .filter(ForecastData.forecast_date <= end_date)
        .all()
    )
    
    # Convert to list of dicts
    forecast_data = [f.to_dict() for f in forecasts]
    
    # Generate report
    report = reports_service.generate_forecast_report(forecast_data)
    
    return jsonify({
        "ok": True,
        "report": report,
        "total_forecasts": len(forecasts)
    })

@admin_bp.get("/api/reports/export/<report_type>")
def api_export_report(report_type: str):
    """Export report (csv/xlsx/pdf) with same filters as JSON endpoints; logs to export_logs."""
    import csv, io
    from sqlalchemy import func, and_, desc
    from datetime import datetime, timedelta

    fmt = request.args.get('format', 'csv').lower()  # csv|xlsx|pdf; default csv
    user_id = (session.get('user') or {}).get('id')

    # Common filters
    from_str = request.args.get('from')
    to_str = request.args.get('to')
    branch_id = request.args.get('branch_id', type=int)
    product_id = request.args.get('product_id', type=int)
    granularity = request.args.get('granularity', 'day')
    model_type = request.args.get('model_type')

    # Build rows based on report_type by reusing logic from JSON endpoints (simplified)
    rows = []
    totals = {}
    filename = "report"

    if report_type == 'sales':
        # Call the same grouping as api_reports_sales
        now = datetime.now()
        start = _parse_date(from_str, now - timedelta(days=30))
        end = _parse_date(to_str, now)
        q = db.session.query(
            func.date(SalesTransaction.transaction_date).label('d'),
            SalesTransaction.branch_id,
            SalesTransaction.product_id,
            func.sum(SalesTransaction.quantity_sold).label('qty'),
            func.sum(SalesTransaction.total_amount).label('amt')
        ).filter(SalesTransaction.transaction_date >= start,
                 SalesTransaction.transaction_date <= end)
        if branch_id:
            q = q.filter(SalesTransaction.branch_id == branch_id)
        if product_id:
            q = q.filter(SalesTransaction.product_id == product_id)
        if granularity == 'month':
            q = q.with_entities(
                func.to_char(SalesTransaction.transaction_date, 'YYYY-MM').label('period'),
                SalesTransaction.branch_id,
                SalesTransaction.product_id,
                func.sum(SalesTransaction.quantity_sold).label('qty'),
                func.sum(SalesTransaction.total_amount).label('amt')
            ).group_by('period', SalesTransaction.branch_id, SalesTransaction.product_id)
            q = q.order_by('period')
        elif granularity == 'week':
            q = q.with_entities(
                func.to_char(SalesTransaction.transaction_date, 'IYYY-IW').label('period'),
                SalesTransaction.branch_id,
                SalesTransaction.product_id,
                func.sum(SalesTransaction.quantity_sold).label('qty'),
                func.sum(SalesTransaction.total_amount).label('amt')
            ).group_by('period', SalesTransaction.branch_id, SalesTransaction.product_id)
            q = q.order_by('period')
        else:
            q = q.group_by('d', SalesTransaction.branch_id, SalesTransaction.product_id)
            q = q.order_by('d')

        branch_map = {b.id: b.name for b in Branch.query.all()}
        product_map = {p.id: p.name for p in Product.query.all()}
        sum_qty = sum_amt = 0.0
        for r in q.all():
            if granularity in ('week','month'):
                period = r[0]
                bid, pid, qty, amt = r[1], r[2], float(r[3] or 0), float(r[4] or 0)
                date_label = period
            else:
                d, bid, pid, qty, amt = r[0], r[1], r[2], float(r[3] or 0), float(r[4] or 0)
                date_label = d.strftime('%Y-%m-%d')
            sum_qty += qty
            sum_amt += amt
            rows.append([date_label, branch_map.get(bid), product_map.get(pid), qty, amt])
        totals = {"sum_qty_kg": sum_qty, "sum_amount": sum_amt}
        filename = f"sales_{granularity}_{start.date()}_{end.date()}_{branch_id or 'all'}"

    elif report_type == 'forecast':
        now = datetime.now().date()
        start = _parse_date(from_str, datetime.combine(now - timedelta(days=30), datetime.min.time())).date()
        end = _parse_date(to_str, datetime.combine(now, datetime.min.time())).date()
        q = db.session.query(
            ForecastData.forecast_date,
            ForecastData.branch_id,
            ForecastData.product_id,
            func.sum(ForecastData.predicted_demand).label('forecast_kg')
        ).filter(and_(ForecastData.forecast_date >= start, ForecastData.forecast_date <= end))
        if branch_id:
            q = q.filter(ForecastData.branch_id == branch_id)
        if product_id:
            q = q.filter(ForecastData.product_id == product_id)
        if model_type:
            q = q.filter(ForecastData.model_type.ilike(model_type))
        q = q.group_by(ForecastData.forecast_date, ForecastData.branch_id, ForecastData.product_id).order_by(ForecastData.forecast_date)
        branch_map = {b.id: b.name for b in Branch.query.all()}
        product_map = {p.id: p.name for p in Product.query.all()}
        sum_f = sum_a = 0.0
        mape_sum = 0.0
        mape_count = 0
        for d, bid, pid, fkg in q.all():
            actual = db.session.query(func.sum(SalesTransaction.quantity_sold)).filter(
                and_(SalesTransaction.branch_id == bid,
                     SalesTransaction.product_id == pid,
                     func.date(SalesTransaction.transaction_date) == d)
            ).scalar() or 0
            fkg = float(fkg or 0)
            akg = float(actual or 0)
            diff = fkg - akg
            ape = abs(diff) / akg * 100 if akg > 0 else None
            if ape is not None:
                mape_sum += ape
                mape_count += 1
            sum_f += fkg
            sum_a += akg
            rows.append([d.strftime('%Y-%m-%d'), branch_map.get(bid), product_map.get(pid), fkg, akg, round(diff,2), round(ape,2) if ape is not None else None])
        totals = {"sum_forecast_kg": sum_f, "sum_actual_kg": sum_a, "mape": round(mape_sum / mape_count, 2) if mape_count>0 else None}
        filename = f"forecast_{start}_{end}_{branch_id or 'all'}"

    elif report_type == 'inventory':
        now = datetime.now().date()
        start = _parse_date(from_str, datetime.combine(now - timedelta(days=30), datetime.min.time())).date()
        end = _parse_date(to_str, datetime.combine(now, datetime.min.time())).date()
        # reuse simplified inventory rows from api_reports_inventory
        recv_q = db.session.query(
            func.date(RestockLog.created_at).label('d'),
            InventoryItem.branch_id,
            InventoryItem.product_id,
            func.sum(RestockLog.qty_kg).label('received_kg')
        ).join(InventoryItem, RestockLog.inventory_item_id == InventoryItem.id)
        if branch_id:
            recv_q = recv_q.filter(InventoryItem.branch_id == branch_id)
        if product_id:
            recv_q = recv_q.filter(InventoryItem.product_id == product_id)
        recv_q = recv_q.filter(func.date(RestockLog.created_at) >= start, func.date(RestockLog.created_at) <= end)
        recv_q = recv_q.group_by('d', InventoryItem.branch_id, InventoryItem.product_id)
        recv_map = {(r.d, r.branch_id, r.product_id): float(r.received_kg or 0) for r in recv_q.all()}
        sold_q = db.session.query(
            func.date(SalesTransaction.transaction_date).label('d'),
            SalesTransaction.branch_id,
            SalesTransaction.product_id,
            func.sum(SalesTransaction.quantity_sold).label('sold_kg')
        ).filter(func.date(SalesTransaction.transaction_date) >= start, func.date(SalesTransaction.transaction_date) <= end)
        if branch_id:
            sold_q = sold_q.filter(SalesTransaction.branch_id == branch_id)
        if product_id:
            sold_q = sold_q.filter(SalesTransaction.product_id == product_id)
        sold_q = sold_q.group_by('d', SalesTransaction.branch_id, SalesTransaction.product_id)
        sold_map = {(r.d, r.branch_id, r.product_id): float(r.sold_kg or 0) for r in sold_q.all()}
        inv_map = {(it.branch_id, it.product_id): float(it.stock_kg or 0) for it in InventoryItem.query.all()}
        branch_map = {b.id: b.name for b in Branch.query.all()}
        product_map = {p.id: p.name for p in Product.query.all()}
        all_keys = set(list(recv_map.keys()) + list(sold_map.keys()))
        for (d, bid, pid) in sorted(all_keys):
            rows.append([
                d.strftime('%Y-%m-%d'), branch_map.get(bid), product_map.get(pid), None,
                recv_map.get((d,bid,pid),0.0), sold_map.get((d,bid,pid),0.0), inv_map.get((bid,pid),0.0)
            ])
        avg_closing = sum(r[-1] for r in rows)/len(rows) if rows else 0
        totals = {"avg_closing_kg": round(avg_closing,2)}
        filename = f"inventory_{start}_{end}_{branch_id or 'all'}"
    else:
        return jsonify({"ok": False, "error": "Invalid report type"}), 400

    # Serialize CSV (xlsx/pdf fallback to CSV for now)
    output = io.StringIO()
    writer = csv.writer(output)
    if report_type == 'sales':
        writer.writerow(['Date/Period','Branch','Product','Qty (kg)','Amount (â‚±)'])
    elif report_type == 'forecast':
        writer.writerow(['Date','Branch','Product','Forecast (kg)','Actual (kg)','Diff (kg)','MAPE %'])
    else:
        writer.writerow(['Date','Branch','Product','Opening (kg)','In (kg)','Out (kg)','Closing (kg)'])
    for row in rows:
        # Fix date formatting for Excel compatibility
        if len(row) > 0 and isinstance(row[0], str) and '-' in str(row[0]):
            # Ensure date is in YYYY-MM-DD format for Excel
            try:
                from datetime import datetime
                date_obj = datetime.strptime(row[0], '%Y-%m-%d')
                row[0] = date_obj.strftime('%Y-%m-%d')
            except:
                pass  # Keep original if parsing fails
        writer.writerow(row)
    csv_data = output.getvalue()

    # Log export
    try:
        log = ExportLog(
            user_id=user_id,
            report_type=report_type,
            filters_json=json.dumps({
                "from": from_str, "to": to_str, "branch_id": branch_id, "product_id": product_id,
                "granularity": granularity, "model_type": model_type
            }),
            file_type=fmt,
            status="completed"
        )
        db.session.add(log)
        db.session.commit()
    except Exception:
        db.session.rollback()

    resp = make_response(csv_data)
    resp.headers['Content-Type'] = 'text/csv'
    resp.headers['Content-Disposition'] = f'attachment; filename={filename}.{fmt}'
    return resp

@admin_bp.get("/api/dashboard/analytics")
def api_dashboard_analytics():
    """Get dashboard analytics data"""
    from models import SalesTransaction, InventoryItem, ForecastData, Branch
    from datetime import datetime, timedelta
    
    # Get date ranges
    today = datetime.now().date()
    week_ago = today - timedelta(days=7)
    month_ago = today - timedelta(days=30)
    
    # Sales analytics
    total_sales_week = (
        SalesTransaction.query
        .filter(SalesTransaction.transaction_date >= week_ago)
        .with_entities(db.func.sum(SalesTransaction.total_amount))
        .scalar() or 0
    )
    
    total_sales_month = (
        SalesTransaction.query
        .filter(SalesTransaction.transaction_date >= month_ago)
        .with_entities(db.func.sum(SalesTransaction.total_amount))
        .scalar() or 0
    )
    
    # Stock analytics
    total_products = InventoryItem.query.count()
    low_stock_items = InventoryItem.query.filter(
        db.and_(
            InventoryItem.stock_kg > 0,
            InventoryItem.stock_kg < InventoryItem.warn_level
        )
    ).count()
    
    out_of_stock_items = InventoryItem.query.filter(
        InventoryItem.stock_kg <= 0
    ).count()
    
    # Forecast analytics
    active_forecasts = ForecastData.query.filter(
        ForecastData.forecast_date >= today
    ).count()
    
    # Branch analytics
    branch_stats = []
    branches = Branch.query.all()
    
    for branch in branches:
        branch_sales = (
            SalesTransaction.query
            .filter_by(branch_id=branch.id)
            .filter(SalesTransaction.transaction_date >= week_ago)
            .with_entities(db.func.sum(SalesTransaction.total_amount))
            .scalar() or 0
        )
        
        branch_products = InventoryItem.query.filter_by(branch_id=branch.id).count()
        
        branch_stats.append({
            "branch_name": branch.name,
            "weekly_sales": round(branch_sales, 2),
            "total_products": branch_products
        })
    
    return jsonify({
        "ok": True,
        "analytics": {
            "sales": {
                "weekly_total": round(total_sales_week, 2),
                "monthly_total": round(total_sales_month, 2),
                "growth_rate": round(((total_sales_week - (total_sales_month/4)) / (total_sales_month/4) * 100), 2) if total_sales_month > 0 else 0
            },
            "inventory": {
                "total_products": total_products,
                "low_stock_items": low_stock_items,
                "out_of_stock_items": out_of_stock_items,
                "low_stock_percentage": round((low_stock_items / total_products * 100), 2) if total_products > 0 else 0
            },
            "forecasts": {
                "active_forecasts": active_forecasts
            },
            "branches": branch_stats
        }
    })

@admin_bp.get("/api/analytics/overview")
def api_analytics_overview():
    """Comprehensive analytics for admin Analytics page.
    Returns:
      - stock_per_branch: [{ branch_id, branch_name, total_stock_kg }]
      - sales_trends_by_branch: { labels: [dates], series: [{ branch_id, branch_name, data: [amount_by_date] }] }
      - forecast_accuracy_by_branch: [{ branch_id, branch_name, accuracy }]
      - inventory_turnover_by_branch: [{ branch_id, branch_name, turnover_ratio }]
      - demand_supply_gaps: [{ branch_id, branch_name, product_id, product_name, stock_kg, predicted_7d, gap_kg, severity }]
    Query params: days (default 30) or start_date/end_date
    """
    try:
        from sqlalchemy import func, and_, desc
        from datetime import date, timedelta, datetime
        from datetime import timezone as tz
        
        # Support both days parameter and date range
        ph_tz = tz(timedelta(hours=8))
        if request.args.get('start_date') and request.args.get('end_date'):
            start_date = datetime.strptime(request.args.get('start_date'), '%Y-%m-%d').date()
            end_date = datetime.strptime(request.args.get('end_date'), '%Y-%m-%d').date()
            days = (end_date - start_date).days + 1
        else:
            days = request.args.get('days', 30, type=int)
            # Use Philippines timezone for date comparison
            now_ph = datetime.now(ph_tz)
            end_date = now_ph.date()  # Today in Philippines time
            start_date = end_date - timedelta(days=days - 1)  # Adjust to include today

        # Branches
        branches = Branch.query.all()
        branch_id_to_name = {b.id: b.name for b in branches}

        # 1) Stock per branch
        stock_rows = (
            db.session.query(InventoryItem.branch_id, func.sum(InventoryItem.stock_kg))
            .group_by(InventoryItem.branch_id)
            .all()
        )
        stock_per_branch = [
            {
                "branch_id": bid,
                "branch_name": branch_id_to_name.get(bid),
                "total_stock_kg": float(total or 0),
            }
            for bid, total in stock_rows
        ]

        # 2) Sales trends by branch (amounts per day)
        # Query all transactions in the date range, then group by Philippines date
        all_sales = db.session.query(SalesTransaction).filter(
            and_(
                SalesTransaction.transaction_date >= datetime.combine(start_date, datetime.min.time()) - timedelta(hours=8),  # Convert PH date start to UTC
                SalesTransaction.transaction_date < datetime.combine(end_date + timedelta(days=1), datetime.min.time()) - timedelta(hours=8)  # Convert PH date end to UTC
            )
        ).all()
        
        # Group by Philippines date and branch
        sales_dict = {}
        for sale in all_sales:
            # Convert UTC datetime to Philippines time and get date
            if sale.transaction_date.tzinfo is None:
                sale_utc = sale.transaction_date.replace(tzinfo=tz.utc)
            else:
                sale_utc = sale.transaction_date
            sale_ph = sale_utc.astimezone(ph_tz)
            sale_date = sale_ph.date()
            
            if start_date <= sale_date <= end_date:
                key = (sale_date, sale.branch_id)
                if key not in sales_dict:
                    sales_dict[key] = 0.0
                sales_dict[key] += float(sale.total_amount)

        # Build date labels
        labels = []
        for i in range(days):
            current_date = start_date + timedelta(days=i)
            if current_date > end_date:
                break
            labels.append(current_date.strftime('%Y-%m-%d'))
        
        # Initialize series per branch
        branch_ids = [b.id for b in branches]
        series_map = {bid: [0.0 for _ in range(len(labels))] for bid in branch_ids}
        idx_map = {labels[i]: i for i in range(len(labels))}

        for (d, bid), amt in sales_dict.items():
            ds = d.strftime('%Y-%m-%d') if hasattr(d, 'strftime') else str(d)
            if ds in idx_map and bid in series_map:
                series_map[bid][idx_map[ds]] = float(amt)

        sales_trends_by_branch = {
            "labels": labels,
            "series": [
                {
                    "branch_id": bid,
                    "branch_name": branch_id_to_name.get(bid),
                    "data": series_map[bid],
                }
                for bid in branch_ids
            ],
        }

        # 3) Forecast accuracy by branch (MAPE over last 30 days)
        # Use Philippines timezone
        today_ph = end_date  # Already calculated as Philippines date
        thirty_days_ago_ph = today_ph - timedelta(days=30)

        forecasts = (
            db.session.query(ForecastData.branch_id, ForecastData.product_id, ForecastData.forecast_date, ForecastData.predicted_demand)
            .filter(and_(ForecastData.forecast_date >= thirty_days_ago_ph, ForecastData.forecast_date <= today_ph))
            .all()
        )

        accuracy_map = {bid: {"mape_sum": 0.0, "count": 0} for bid in branch_ids}
        for bid, pid, fdate, predicted in forecasts:
            # Convert forecast date to UTC datetime range for Philippines timezone
            fdate_start_ph = datetime.combine(fdate, datetime.min.time()).replace(tzinfo=ph_tz)
            fdate_end_ph = datetime.combine(fdate, datetime.max.time()).replace(tzinfo=ph_tz)
            fdate_start_utc = fdate_start_ph.astimezone(tz.utc).replace(tzinfo=None)
            fdate_end_utc = fdate_end_ph.astimezone(tz.utc).replace(tzinfo=None)
            
            actual = (
                db.session.query(func.sum(SalesTransaction.quantity_sold))
                .filter(
                    and_(
                        SalesTransaction.branch_id == bid,
                        SalesTransaction.product_id == pid,
                        SalesTransaction.transaction_date >= fdate_start_utc,
                        SalesTransaction.transaction_date <= fdate_end_utc,
                    )
                )
                .scalar()
                or 0
            )
            if actual > 0:
                mape = abs((predicted or 0) - actual) / actual * 100.0
                accuracy_map[bid]["mape_sum"] += mape
                accuracy_map[bid]["count"] += 1

        forecast_accuracy_by_branch = []
        for bid in branch_ids:
            cnt = accuracy_map[bid]["count"]
            acc = 100.0 - (accuracy_map[bid]["mape_sum"] / cnt) if cnt > 0 else 0.0
            forecast_accuracy_by_branch.append({
                "branch_id": bid,
                "branch_name": branch_id_to_name.get(bid),
                "accuracy": round(acc, 2),
            })

        # 4) Inventory turnover by branch (approx): monthly qty sold / current stock
        month_ago_ph = today_ph - timedelta(days=30)
        month_ago_start_ph = datetime.combine(month_ago_ph, datetime.min.time()).replace(tzinfo=ph_tz)
        month_ago_start_utc = month_ago_start_ph.astimezone(tz.utc).replace(tzinfo=None)
        
        qty_rows = (
            db.session.query(SalesTransaction.branch_id, func.sum(SalesTransaction.quantity_sold))
            .filter(SalesTransaction.transaction_date >= month_ago_start_utc)
            .group_by(SalesTransaction.branch_id)
            .all()
        )
        qty_map = {bid: float(q or 0) for bid, q in qty_rows}
        stock_map = {row[0]: float(row[1] or 0) for row in stock_rows}
        inventory_turnover_by_branch = []
        for bid in branch_ids:
            sold = qty_map.get(bid, 0.0)
            stock = stock_map.get(bid, 0.0)
            turnover = (sold / stock) if stock > 0 else 0.0
            inventory_turnover_by_branch.append({
                "branch_id": bid,
                "branch_name": branch_id_to_name.get(bid),
                "turnover_ratio": round(turnover, 2),
            })

        # 4b) Top products per branch (this month)
        current_month = today_ph.month
        current_year = today_ph.year
        top_products_per_branch = {}
        for bid in branch_ids:
            rows = (
                db.session.query(Product.name, func.sum(SalesTransaction.quantity_sold).label('qty'), func.sum(SalesTransaction.total_amount).label('amt'))
                .join(Product, Product.id == SalesTransaction.product_id)
                .filter(
                    and_(
                        SalesTransaction.branch_id == bid,
                        func.extract('month', SalesTransaction.transaction_date) == current_month,
                        func.extract('year', SalesTransaction.transaction_date) == current_year,
                    )
                )
                .group_by(Product.id, Product.name)
                .order_by(desc('qty'))
                .limit(5)
                .all()
            )
            top_products_per_branch[bid] = [
                {"name": n, "quantity": float(q or 0), "sales": float(a or 0)} for n, q, a in rows
            ]

        # 5) Demand-supply gaps: next 7 days forecast sum per product vs current stock
        next7 = today_ph + timedelta(days=7)
        forecast_next = (
            db.session.query(
                ForecastData.branch_id,
                ForecastData.product_id,
                func.sum(ForecastData.predicted_demand).label('predicted')
            )
            .filter(and_(ForecastData.forecast_date >= today_ph, ForecastData.forecast_date <= next7))
            .group_by(ForecastData.branch_id, ForecastData.product_id)
            .all()
        )
        # Current stock per (branch, product)
        inv_rows = (
            db.session.query(InventoryItem.branch_id, InventoryItem.product_id, InventoryItem.stock_kg)
            .all()
        )
        inv_map = {(b, p): float(s or 0) for b, p, s in inv_rows}
        pid_to_name = {p.id: p.name for p in Product.query.all()}

        demand_supply_gaps = []
        for bid, pid, pred in forecast_next:
            stock = inv_map.get((bid, pid), 0.0)
            gap = float(pred or 0) - stock
            if gap > 0:  # only gaps where demand exceeds supply
                severity = "critical" if gap > stock else "warning"
                demand_supply_gaps.append({
                    "branch_id": bid,
                    "branch_name": branch_id_to_name.get(bid),
                    "product_id": pid,
                    "product_name": pid_to_name.get(pid),
                    "stock_kg": stock,
                    "predicted_7d": float(pred or 0),
                    "gap_kg": round(gap, 2),
                    "severity": severity,
                })

        return jsonify({
            "ok": True,
            "analytics": {
                "stock_per_branch": stock_per_branch,
                "sales_trends_by_branch": sales_trends_by_branch,
                "forecast_accuracy_by_branch": forecast_accuracy_by_branch,
                "inventory_turnover_by_branch": inventory_turnover_by_branch,
                "top_products_per_branch": top_products_per_branch,
                "demand_supply_gaps": demand_supply_gaps,
            }
        })
    except Exception as e:
        import traceback
        print(f"Error in api_analytics_overview: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            "ok": False,
            "error": f"Failed to load analytics data: {str(e)}"
        }), 500

# ========== DASHBOARD API ENDPOINTS ==========

@admin_bp.get("/api/dashboard/kpis")
# @cache.cached(timeout=300)  # Temporarily disable cache for debugging
def api_dashboard_kpis():
    """Get KPI data for dashboard"""
    try:
        from datetime import datetime, date, timedelta
        from sqlalchemy import func, and_, text
        
        # Get query parameters for branch filtering
        branch_id = request.args.get('branch_id', type=int)
        
        # Get current date and month
        today = date.today()
        current_month = today.month
        current_year = today.year
        
        # Initialize default values
        today_sales = 0
        month_sales = 0
        total_sales = 0
        low_stock_count = 0
        forecast_accuracy = 0
        total_orders = 0
        
        try:
            # Base queries
            sales_query = db.session.query(SalesTransaction)
            inventory_query = db.session.query(InventoryItem)
            forecast_query = db.session.query(ForecastData)
            
            # Apply branch filter if provided
            if branch_id:
                sales_query = sales_query.filter(SalesTransaction.branch_id == branch_id)
                inventory_query = inventory_query.filter(InventoryItem.branch_id == branch_id)
                forecast_query = forecast_query.filter(ForecastData.branch_id == branch_id)
            
            # Today's sales
            today_sales = sales_query.filter(
                func.date(SalesTransaction.transaction_date) == today
            ).with_entities(func.sum(SalesTransaction.total_amount)).scalar() or 0
            
            # This month's sales
            month_sales = sales_query.filter(
                and_(
                    func.extract('month', SalesTransaction.transaction_date) == current_month,
                    func.extract('year', SalesTransaction.transaction_date) == current_year
                )
            ).with_entities(func.sum(SalesTransaction.total_amount)).scalar() or 0
            
            # Total sales (all time)
            total_sales = sales_query.with_entities(func.sum(SalesTransaction.total_amount)).scalar() or 0
            
            # Total Orders (all time for admin - all branches)
            total_orders = sales_query.count()
            
        except Exception as e:
            print(f"DEBUG KPI: Error in sales/inventory queries: {e}")
            import traceback
            traceback.print_exc()
        
        try:
            # Low stock count - items where stock is below warning level
            low_stock_count = inventory_query.filter(
                and_(
                    InventoryItem.warn_level.isnot(None),
                    InventoryItem.stock_kg <= InventoryItem.warn_level
                )
            ).count()
            
            # If no warning levels set, use a default threshold (10% of average stock)
            if low_stock_count == 0:
                avg_stock = inventory_query.with_entities(func.avg(InventoryItem.stock_kg)).scalar() or 0
                if avg_stock > 0:
                    default_threshold = avg_stock * 0.1  # 10% of average stock
                    low_stock_count = inventory_query.filter(
                        InventoryItem.stock_kg <= default_threshold
                    ).count()
        except Exception as e:
            print(f"DEBUG KPI: Error calculating low stock: {e}")
            low_stock_count = 0
        
        try:
            # Forecast accuracy (MAPE - Mean Absolute Percentage Error)
            # Get last 30 days of forecasts and actual sales
            thirty_days_ago = today - timedelta(days=30)
            
            # Get forecast data for last 30 days
            forecasts = forecast_query.filter(
                and_(
                    ForecastData.forecast_date >= thirty_days_ago,
                    ForecastData.forecast_date <= today
                )
            ).all()
            
            # Calculate MAPE
            total_mape = 0
            forecast_count = 0
            
            for forecast in forecasts:
                try:
                    # Get actual sales for the forecast date
                    actual_sales = sales_query.filter(
                        and_(
                            SalesTransaction.product_id == forecast.product_id,
                            func.date(SalesTransaction.transaction_date) == forecast.forecast_date
                        )
                    ).with_entities(func.sum(SalesTransaction.quantity_sold)).scalar() or 0
                    
                    if actual_sales > 0:
                        mape = abs(forecast.predicted_demand - actual_sales) / actual_sales * 100
                        total_mape += mape
                        forecast_count += 1
                except Exception as e:
                    print(f"DEBUG KPI: Error processing forecast {forecast.id}: {e}")
                    continue
            
            # Calculate forecast accuracy, clamped between 0% and 100%
            if forecast_count > 0:
                avg_mape = total_mape / forecast_count
                forecast_accuracy = max(0, min(100, 100 - avg_mape))  # Clamp between 0 and 100
            else:
                forecast_accuracy = 0
        except Exception as e:
            print(f"DEBUG KPI: Error calculating forecast accuracy: {e}")
            forecast_accuracy = 0
        
        # Debug logging
        print(f"DEBUG KPI: Today's date: {today}")
        print(f"DEBUG KPI: Branch filter: {branch_id if branch_id else 'ALL BRANCHES'}")
        print(f"DEBUG KPI: Today's sales: {today_sales}, Month sales: {month_sales}, Total sales: {total_sales}")
        print(f"DEBUG KPI: Low stock: {low_stock_count}, Orders: {total_orders}, Accuracy: {forecast_accuracy}")
        
        return jsonify({
            "ok": True,
            "kpis": {
                "today_sales": float(today_sales),
                "month_sales": float(month_sales),
                "total_sales": float(total_sales),
                "low_stock_count": int(low_stock_count),
                "forecast_accuracy": round(forecast_accuracy, 2),
                "total_orders": int(total_orders)
            }
        })
    except Exception as e:
        print(f"DEBUG KPI: Critical error in api_dashboard_kpis: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": str(e),
            "kpis": {
                "today_sales": 0,
                "month_sales": 0,
                "total_sales": 0,
                "low_stock_count": 0,
                "forecast_accuracy": 0,
                "total_orders": 0
            }
        }), 500

@admin_bp.get("/api/dashboard/charts")
def api_dashboard_charts():
    """Get chart data for dashboard"""
    try:
        from datetime import datetime, date, timedelta
        from sqlalchemy import func, and_, desc
        
        # Get query parameters
        branch_id = request.args.get('branch_id', type=int)
        product_id = request.args.get('product_id', type=int)
        
        # Handle date range - support both days and custom from/to dates
        from_str = request.args.get('from')
        to_str = request.args.get('to')
        
        # Use Philippines timezone for date comparison
        from datetime import timezone as tz
        ph_tz = tz(timedelta(hours=8))
        now_ph = datetime.now(ph_tz)
        
        if from_str and to_str:
            # Custom date range
            try:
                start_date = datetime.strptime(from_str, '%Y-%m-%d').date()
                end_date = datetime.strptime(to_str, '%Y-%m-%d').date()
                # Ensure end_date is not in the future
                if end_date > now_ph.date():
                    end_date = now_ph.date()
                # Calculate days for other parts of the function
                days = (end_date - start_date).days + 1
            except (ValueError, TypeError):
                # Fallback to default 30 days
                end_date = now_ph.date()
                start_date = end_date - timedelta(days=29)
                days = 30
        else:
            # Handle days parameter - ensure it's an integer
            days_param = request.args.get('days', '30')
            try:
                days = int(days_param)
                if days <= 0:
                    days = 30
            except (ValueError, TypeError):
                days = 30
            end_date = now_ph.date()  # Today in Philippines time
            start_date = end_date - timedelta(days=days - 1)  # Adjust to include today
        
        # Base queries
        sales_query = db.session.query(SalesTransaction)
        forecast_query = db.session.query(ForecastData)
        
        # Apply filters
        if branch_id:
            sales_query = sales_query.filter(SalesTransaction.branch_id == branch_id)
            forecast_query = forecast_query.filter(ForecastData.branch_id == branch_id)
        
        if product_id:
            sales_query = sales_query.filter(SalesTransaction.product_id == product_id)
            forecast_query = forecast_query.filter(ForecastData.product_id == product_id)
        
        # Get all branches for branch breakdown
        all_branches = Branch.query.all()
        branch_map = {b.id: b.name for b in all_branches}
        
        # Query all transactions in the date range, then group by Philippines date and branch
        # Since transactions are stored as naive UTC, we need to convert to Philippines time for date extraction
        all_sales = sales_query.filter(
            and_(
                SalesTransaction.transaction_date >= datetime.combine(start_date, datetime.min.time()) - timedelta(hours=8),  # Convert PH date start to UTC
                SalesTransaction.transaction_date < datetime.combine(end_date + timedelta(days=1), datetime.min.time()) - timedelta(hours=8)  # Convert PH date end to UTC
            )
        ).all()
        
        # Group by date and branch (if no branch_id filter)
        if branch_id:
            # Single branch - aggregate all data
            sales_trend_dict = {}
            for sale in all_sales:
                # Convert UTC datetime to Philippines time and get date
                if sale.transaction_date.tzinfo is None:
                    # Naive datetime, assume UTC
                    sale_utc = sale.transaction_date.replace(tzinfo=tz.utc)
                else:
                    sale_utc = sale.transaction_date
                sale_ph = sale_utc.astimezone(ph_tz)
                sale_date = sale_ph.date()
                
                if start_date <= sale_date <= end_date:
                    if sale_date not in sales_trend_dict:
                        sales_trend_dict[sale_date] = {'sales': 0.0, 'quantity': 0.0}
                    sales_trend_dict[sale_date]['sales'] += float(sale.total_amount)
                    sales_trend_dict[sale_date]['quantity'] += float(sale.quantity_sold)
            
            # Fill in missing dates with zero values - include today
            sales_trend_filled = []
            for i in range(days):
                current_date = start_date + timedelta(days=i)
                # Ensure we don't go past today
                if current_date > end_date:
                    break
                
                sales_trend_filled.append({
                    'date': current_date.strftime('%Y-%m-%d'),
                    'sales': sales_trend_dict.get(current_date, {'sales': 0.0})['sales'],
                    'quantity': sales_trend_dict.get(current_date, {'quantity': 0.0})['quantity']
                })
        else:
            # All branches - group by branch and date
            sales_trend_by_branch = {}  # {branch_id: {date: {sales, quantity}}}
            
            for sale in all_sales:
                # Convert UTC datetime to Philippines time and get date
                if sale.transaction_date.tzinfo is None:
                    sale_utc = sale.transaction_date.replace(tzinfo=tz.utc)
                else:
                    sale_utc = sale.transaction_date
                sale_ph = sale_utc.astimezone(ph_tz)
                sale_date = sale_ph.date()
                
                if start_date <= sale_date <= end_date:
                    bid = sale.branch_id
                    if bid not in sales_trend_by_branch:
                        sales_trend_by_branch[bid] = {}
                    if sale_date not in sales_trend_by_branch[bid]:
                        sales_trend_by_branch[bid][sale_date] = {'sales': 0.0, 'quantity': 0.0}
                    sales_trend_by_branch[bid][sale_date]['sales'] += float(sale.total_amount)
                    sales_trend_by_branch[bid][sale_date]['quantity'] += float(sale.quantity_sold)
            
            # Format as list of branch datasets
            sales_trend_filled = []
            for bid, branch_name in branch_map.items():
                branch_data = []
                for i in range(days):
                    current_date = start_date + timedelta(days=i)
                    if current_date > end_date:
                        break
                    
                    branch_data.append({
                        'date': current_date.strftime('%Y-%m-%d'),
                        'sales': sales_trend_by_branch.get(bid, {}).get(current_date, {'sales': 0.0})['sales'],
                        'quantity': sales_trend_by_branch.get(bid, {}).get(current_date, {'quantity': 0.0})['quantity']
                    })
                
                sales_trend_filled.append({
                    'branch_id': bid,
                    'branch_name': branch_name,
                    'data': branch_data
                })
        
        # Forecast vs Actual data
        if branch_id:
            # Single branch - aggregate
            forecast_vs_actual = []
            for i in range(days):
                current_date = start_date + timedelta(days=i)
                if current_date > end_date:
                    break
                
                # Get actual sales for this date (use Philippines timezone)
                current_date_start_ph = datetime.combine(current_date, datetime.min.time()).replace(tzinfo=ph_tz)
                current_date_end_ph = datetime.combine(current_date, datetime.max.time()).replace(tzinfo=ph_tz)
                current_date_start_utc = current_date_start_ph.astimezone(tz.utc).replace(tzinfo=None)
                current_date_end_utc = current_date_end_ph.astimezone(tz.utc).replace(tzinfo=None)
                
                actual_sales = sales_query.filter(
                    and_(
                        SalesTransaction.transaction_date >= current_date_start_utc,
                        SalesTransaction.transaction_date <= current_date_end_utc
                    )
                ).with_entities(
                    func.sum(SalesTransaction.quantity_sold)
                ).scalar() or 0
                
                # Get forecast for this date - sum all forecasts for this date
                forecast_sales = forecast_query.filter(
                    ForecastData.forecast_date == current_date
                ).with_entities(
                    func.sum(ForecastData.predicted_demand)
                ).scalar() or 0
                
                forecast_vs_actual.append({
                    'date': current_date.strftime('%Y-%m-%d'),
                    'actual': float(actual_sales),
                    'forecast': float(forecast_sales)
                })
        else:
            # All branches - group by branch
            forecast_vs_actual_by_branch = {}  # {branch_id: [{date, actual, forecast}]}
            
            for bid in branch_map.keys():
                forecast_vs_actual_by_branch[bid] = []
                branch_sales_query = db.session.query(SalesTransaction).filter(
                    SalesTransaction.branch_id == bid
                )
                branch_forecast_query = db.session.query(ForecastData).filter(
                    ForecastData.branch_id == bid
                )
                
                if product_id:
                    branch_sales_query = branch_sales_query.filter(SalesTransaction.product_id == product_id)
                    branch_forecast_query = branch_forecast_query.filter(ForecastData.product_id == product_id)
                
                for i in range(days):
                    current_date = start_date + timedelta(days=i)
                    if current_date > end_date:
                        break
                    
                    # Get actual sales for this date and branch
                    current_date_start_ph = datetime.combine(current_date, datetime.min.time()).replace(tzinfo=ph_tz)
                    current_date_end_ph = datetime.combine(current_date, datetime.max.time()).replace(tzinfo=ph_tz)
                    current_date_start_utc = current_date_start_ph.astimezone(tz.utc).replace(tzinfo=None)
                    current_date_end_utc = current_date_end_ph.astimezone(tz.utc).replace(tzinfo=None)
                    
                    actual_sales = branch_sales_query.filter(
                        and_(
                            SalesTransaction.transaction_date >= current_date_start_utc,
                            SalesTransaction.transaction_date <= current_date_end_utc
                        )
                    ).with_entities(
                        func.sum(SalesTransaction.quantity_sold)
                    ).scalar() or 0
                    
                    # Get forecast for this date and branch
                    forecast_sales = branch_forecast_query.filter(
                        ForecastData.forecast_date == current_date
                    ).with_entities(
                        func.sum(ForecastData.predicted_demand)
                    ).scalar() or 0
                    
                    forecast_vs_actual_by_branch[bid].append({
                        'date': current_date.strftime('%Y-%m-%d'),
                        'actual': float(actual_sales),
                        'forecast': float(forecast_sales)
                    })
            
            # Format as list of branch datasets
            forecast_vs_actual = []
            for bid, branch_name in branch_map.items():
                forecast_vs_actual.append({
                    'branch_id': bid,
                    'branch_name': branch_name,
                    'data': forecast_vs_actual_by_branch.get(bid, [])
                })
        
        # Top 5 products for the specified date range
        # Convert Philippines date range to UTC datetime range
        range_start_ph = datetime.combine(start_date, datetime.min.time()).replace(tzinfo=ph_tz)
        range_end_ph = datetime.combine(end_date, datetime.max.time()).replace(tzinfo=ph_tz)
        range_start_utc = range_start_ph.astimezone(tz.utc).replace(tzinfo=None)
        range_end_utc = range_end_ph.astimezone(tz.utc).replace(tzinfo=None)
        
        top_products_query = db.session.query(
            Product.name,
            func.sum(SalesTransaction.quantity_sold).label('total_quantity'),
            func.sum(SalesTransaction.total_amount).label('total_sales')
        ).join(
            SalesTransaction, Product.id == SalesTransaction.product_id
        ).filter(
            and_(
                SalesTransaction.transaction_date >= range_start_utc,
                SalesTransaction.transaction_date <= range_end_utc
            )
        )
        
        if branch_id:
            top_products_query = top_products_query.filter(SalesTransaction.branch_id == branch_id)
        
        top_products = top_products_query.group_by(
            Product.id, Product.name
        ).order_by(
            desc('total_quantity')
        ).limit(5).all()
        
        # Debug logging
        print(f"DEBUG: Top products query for branch_id={branch_id}, days={days} ({start_date} to {end_date})")
        print(f"DEBUG: Found {len(top_products)} products")
        for i, product in enumerate(top_products):
            print(f"DEBUG: Product {i+1}: {product.name} - Qty: {product.total_quantity}, Sales: {product.total_sales}")
        
        # Format top products for response
        top_products_formatted = []
        for row in top_products:
            top_products_formatted.append({
                'name': row.name,
                'quantity': float(row.total_quantity),
                'sales': float(row.total_sales)
            })
        
        return jsonify({
            "ok": True,
            "charts": {
                "sales_trend": sales_trend_filled,
                "forecast_vs_actual": forecast_vs_actual,
                "top_products": top_products_formatted
            }
        })
    except Exception as e:
        import traceback
        print(f"Error in api_dashboard_charts: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            "ok": False,
            "error": f"Failed to load chart data: {str(e)}"
        }), 500

@admin_bp.get("/api/dashboard/key-metrics")
def api_dashboard_key_metrics():
    """Get key metrics for dashboard (Revenue, Orders, Avg Order Value, Customer Satisfaction)"""
    from datetime import datetime, date, timedelta
    from sqlalchemy import func, and_, desc
    
    # Get current date and previous period for comparison
    today = date.today()
    current_month = today.month
    current_year = today.year
    
    # Previous month for comparison
    if current_month == 1:
        prev_month = 12
        prev_year = current_year - 1
    else:
        prev_month = current_month - 1
        prev_year = current_year
    
    # Current month metrics
    current_sales = db.session.query(SalesTransaction).filter(
        and_(
            func.extract('month', SalesTransaction.transaction_date) == current_month,
            func.extract('year', SalesTransaction.transaction_date) == current_year
        )
    ).with_entities(
        func.sum(SalesTransaction.total_amount).label('total_sales'),
        func.count(SalesTransaction.id).label('order_count'),
        func.avg(SalesTransaction.total_amount).label('avg_order_value')
    ).first()
    
    # Previous month metrics for comparison
    prev_sales = db.session.query(SalesTransaction).filter(
        and_(
            func.extract('month', SalesTransaction.transaction_date) == prev_month,
            func.extract('year', SalesTransaction.transaction_date) == prev_year
        )
    ).with_entities(
        func.sum(SalesTransaction.total_amount).label('total_sales'),
        func.count(SalesTransaction.id).label('order_count'),
        func.avg(SalesTransaction.total_amount).label('avg_order_value')
    ).first()
    
    # Calculate metrics
    current_revenue = float(current_sales.total_sales or 0)
    current_orders = int(current_sales.order_count or 0)
    current_avg_order = float(current_sales.avg_order_value or 0)
    
    prev_revenue = float(prev_sales.total_sales or 0)
    prev_orders = int(prev_sales.order_count or 0)
    prev_avg_order = float(prev_sales.avg_order_value or 0)
    
    # Calculate percentage changes
    revenue_change = ((current_revenue - prev_revenue) / prev_revenue * 100) if prev_revenue > 0 else 0
    orders_change = ((current_orders - prev_orders) / prev_orders * 100) if prev_orders > 0 else 0
    avg_order_change = ((current_avg_order - prev_avg_order) / prev_avg_order * 100) if prev_avg_order > 0 else 0
    
    # Customer satisfaction (simulated based on forecast accuracy)
    forecast_accuracy = db.session.query(func.avg(ForecastData.accuracy_score)).scalar() or 0
    customer_satisfaction = min(5.0, max(1.0, 1.0 + (forecast_accuracy / 100) * 4))  # Scale to 1-5
    satisfaction_change = 0.2  # Simulated improvement
    
    return jsonify({
        "ok": True,
        "metrics": {
            "revenue": {
                "value": current_revenue,
                "change": round(revenue_change, 1),
                "formatted": f"â‚±{current_revenue:,.0f}"
            },
            "orders": {
                "value": current_orders,
                "change": round(orders_change, 1),
                "formatted": f"{current_orders:,}"
            },
            "avg_order_value": {
                "value": current_avg_order,
                "change": round(avg_order_change, 1),
                "formatted": f"â‚±{current_avg_order:,.0f}"
            },
            "customer_satisfaction": {
                "value": customer_satisfaction,
                "change": satisfaction_change,
                "formatted": f"{customer_satisfaction:.1f}/5"
            }
        }
    })

@admin_bp.get("/api/dashboard/recent-activity")
def api_dashboard_recent_activity():
    """Get recent activity logs from admin and managers"""
    from datetime import datetime, timedelta
    from models import ActivityLog
    
    # Get activities from the last 24 hours
    since = datetime.utcnow() - timedelta(hours=24)
    
    # Get recent activities from ActivityLog
    recent_activities = db.session.query(ActivityLog).filter(
        ActivityLog.created_at >= since
    ).order_by(ActivityLog.created_at.desc()).limit(10).all()
    
    activities = []
    
    # Map activity types to icons and titles
    activity_mapping = {
        "password_reset_success": {"icon": "ðŸ”", "title": "Password Reset"},
        "password_reset_failed": {"icon": "âŒ", "title": "Password Reset Failed"},
        "email_change_success": {"icon": "ðŸ“§", "title": "Email Updated"},
        "email_change_failed": {"icon": "âŒ", "title": "Email Change Failed"},
        "product_add": {"icon": "âž•", "title": "Product Added"},
        "product_edit": {"icon": "âœï¸", "title": "Product Edited"},
        "product_delete": {"icon": "ðŸ—‘ï¸", "title": "Product Deleted"},
        "restock": {"icon": "ðŸ“¦", "title": "Stock Restocked"},
        "sale": {"icon": "ðŸ’°", "title": "Sale Completed"},
        "user_login": {"icon": "ðŸ‘¤", "title": "User Login"},
        "user_management_user_create": {"icon": "ðŸ‘¥", "title": "User Created"},
        "user_management_user_edit": {"icon": "âœï¸", "title": "User Updated"},
        "user_management_user_delete": {"icon": "ðŸ—‘ï¸", "title": "User Deleted"},
        "system_report": {"icon": "ðŸ“Š", "title": "Report Generated"},
        "system_sync": {"icon": "ðŸ”„", "title": "System Sync"}
    }
    
    # Add activities from ActivityLog
    for activity in recent_activities:
        mapping = activity_mapping.get(activity.action, {"icon": "ðŸ“", "title": "System Activity"})
        
        activities.append({
            "icon": mapping["icon"],
            "title": mapping["title"],
            "description": activity.description,
            "time": activity.created_at.strftime("%H:%M"),
            "time_ago": activity.get_time_ago(),
            "type": activity.action.split('_')[0] if '_' in activity.action else activity.action
        })
    
    # If no activities, add a default message
    if not activities:
        activities.append({
            "icon": "â„¹ï¸",
            "title": "No Recent Activity",
            "description": "No activities found in the last 24 hours",
            "time": datetime.utcnow().strftime("%H:%M"),
            "time_ago": "Just now",
            "type": "info"
        })
    
    # Sort by time (most recent first) and limit to 5
    activities.sort(key=lambda x: x['time'], reverse=True)
    activities = activities[:5]
    
    return jsonify({
        "ok": True,
        "activities": activities
    })

@admin_bp.get("/api/dashboard/alerts")
def api_dashboard_alerts():
    """Generate dynamic alerts based on system state"""
    from datetime import datetime, timedelta
    from sqlalchemy import func, and_, or_
    from models import InventoryItem, SalesTransaction, Branch, RestockLog, Product
    
    alerts = []
    now = datetime.utcnow()
    
    try:
        # 1. LOW STOCK ALERTS (Critical) - Items below warn_level
        low_stock_items = db.session.query(InventoryItem).filter(
            and_(
                InventoryItem.stock_kg > 0,
                InventoryItem.stock_kg < InventoryItem.warn_level,
                InventoryItem.warn_level.isnot(None)
            )
        ).all()
        
        if low_stock_items:
            low_stock_count = len(low_stock_items)
            product_names = [item.product.name if item.product else "Unknown" for item in low_stock_items[:3]]
            product_list = ", ".join(product_names)
            if low_stock_count > 3:
                product_list += f" and {low_stock_count - 3} more"
            
            alerts.append({
                "type": "critical",
                "icon": "âš ï¸",
                "title": "Low Stock Alert",
                "description": f"{low_stock_count} item(s) below safety stock: {product_list}",
                "time_ago": "Just now",
                "count": low_stock_count
            })
        
        # 2. OUT OF STOCK ALERTS (Critical) - Items with 0 stock
        out_of_stock_items = db.session.query(InventoryItem).filter(
            InventoryItem.stock_kg <= 0
        ).all()
        
        if out_of_stock_items:
            out_of_stock_count = len(out_of_stock_items)
            product_names = [item.product.name if item.product else "Unknown" for item in out_of_stock_items[:3]]
            product_list = ", ".join(product_names)
            if out_of_stock_count > 3:
                product_list += f" and {out_of_stock_count - 3} more"
            
            alerts.append({
                "type": "critical",
                "icon": "ðŸš¨",
                "title": "Out of Stock",
                "description": f"{out_of_stock_count} item(s) completely out of stock: {product_list}",
                "time_ago": "Just now",
                "count": out_of_stock_count
            })
        
        # 3. HIGH STOCK / OVERSTOCK ALERTS (Warning) - Items significantly above auto_level
        high_stock_items = db.session.query(InventoryItem).filter(
            and_(
                InventoryItem.auto_level.isnot(None),
                InventoryItem.stock_kg > (InventoryItem.auto_level * 2)  # 2x above auto level
            )
        ).limit(5).all()
        
        if high_stock_items:
            high_stock_count = len(high_stock_items)
            product_names = [item.product.name if item.product else "Unknown" for item in high_stock_items[:2]]
            product_list = ", ".join(product_names)
            if high_stock_count > 2:
                product_list += f" and {high_stock_count - 2} more"
            
            alerts.append({
                "type": "warning",
                "icon": "ðŸ“¦",
                "title": "Overstock Alert",
                "description": f"{high_stock_count} item(s) with excess inventory: {product_list}",
                "time_ago": "Just now",
                "count": high_stock_count
            })
        
        # 4. SLOW MOVING INVENTORY (Warning) - Products not sold in last 7 days
        seven_days_ago = now - timedelta(days=7)
        recent_sales_product_ids = db.session.query(
            func.distinct(SalesTransaction.product_id)
        ).filter(
            SalesTransaction.transaction_date >= seven_days_ago
        ).all()
        recent_product_ids = [pid[0] for pid in recent_sales_product_ids if pid[0]]
        
        if recent_product_ids:
            slow_moving = db.session.query(InventoryItem).filter(
                and_(
                    InventoryItem.stock_kg > 0,
                    ~InventoryItem.product_id.in_(recent_product_ids)
                )
            ).limit(5).all()
        else:
            # If no sales at all, check items with stock
            slow_moving = db.session.query(InventoryItem).filter(
                InventoryItem.stock_kg > 0
            ).limit(5).all()
        
        if slow_moving:
            product_names = [item.product.name if item.product else "Unknown" for item in slow_moving[:2]]
            product_list = ", ".join(product_names)
            if len(slow_moving) > 2:
                product_list += f" and {len(slow_moving) - 2} more"
            
            alerts.append({
                "type": "warning",
                "icon": "ðŸ“‰",
                "title": "Slow Moving Inventory",
                "description": f"{len(slow_moving)} product(s) not sold in last 7 days: {product_list}",
                "time_ago": "1h ago",
                "count": len(slow_moving)
            })
        
        # 5. DEMAND SPIKE (Info) - Products with unusually high sales in last 24 hours
        one_day_ago = now - timedelta(days=1)
        spike_threshold = 100  # kg threshold for spike detection
        
        recent_sales = db.session.query(
            SalesTransaction.product_id,
            func.sum(SalesTransaction.quantity_sold).label('total_sold')
        ).filter(
            SalesTransaction.transaction_date >= one_day_ago
        ).group_by(SalesTransaction.product_id).having(
            func.sum(SalesTransaction.quantity_sold) > spike_threshold
        ).limit(3).all()
        
        if recent_sales:
            spike_products = []
            for product_id, total_sold in recent_sales:
                product = db.session.query(Product).get(product_id)
                if product:
                    spike_products.append(f"{product.name} ({total_sold:.1f} kg)")
            
            if spike_products:
                alerts.append({
                    "type": "info",
                    "icon": "ðŸ“ˆ",
                    "title": "Demand Spike",
                    "description": f"High demand detected: {', '.join(spike_products[:2])}",
                    "time_ago": "2h ago",
                    "count": len(spike_products)
                })
        
        # 6. BRANCH STATUS ALERTS (Warning) - Branches in maintenance or closed
        problem_branches = db.session.query(Branch).filter(
            Branch.status.in_(['maintenance', 'closed'])
        ).all()
        
        if problem_branches:
            branch_names = [branch.name for branch in problem_branches]
            alerts.append({
                "type": "warning",
                "icon": "ðŸ¢",
                "title": "Branch Status Alert",
                "description": f"Branch(es) with issues: {', '.join(branch_names)}",
                "time_ago": "Just now",
                "count": len(problem_branches)
            })
        
        # 7. NO SALES ACTIVITY (Warning) - Branches with no sales in last 3 days
        three_days_ago = now - timedelta(days=3)
        branches_with_sales = db.session.query(
            func.distinct(SalesTransaction.branch_id)
        ).filter(
            SalesTransaction.transaction_date >= three_days_ago
        ).all()
        active_branch_ids = [bid[0] for bid in branches_with_sales if bid[0]]
        
        if active_branch_ids:
            inactive_branches = db.session.query(Branch).filter(
                ~Branch.id.in_(active_branch_ids),
                Branch.status == 'operational'
            ).all()
        else:
            inactive_branches = db.session.query(Branch).filter(
                Branch.status == 'operational'
            ).all()
        
        if inactive_branches:
            branch_names = [branch.name for branch in inactive_branches[:3]]
            branch_list = ", ".join(branch_names)
            if len(inactive_branches) > 3:
                branch_list += f" and {len(inactive_branches) - 3} more"
            
            alerts.append({
                "type": "warning",
                "icon": "ðŸ“Š",
                "title": "No Sales Activity",
                "description": f"Branch(es) with no sales in 3 days: {branch_list}",
                "time_ago": "3h ago",
                "count": len(inactive_branches)
            })
        
        # Sort alerts by priority: critical > warning > info
        priority_order = {"critical": 0, "warning": 1, "info": 2}
        alerts.sort(key=lambda x: priority_order.get(x["type"], 3))
        
        # Limit to top 8 alerts
        alerts = alerts[:8]
        
    except Exception as e:
        print(f"Error generating alerts: {e}")
        import traceback
        traceback.print_exc()
        # Return at least one error alert
        alerts = [{
            "type": "warning",
            "icon": "âš ï¸",
            "title": "Alert System Error",
            "description": "Unable to generate some alerts. Please check system logs.",
            "time_ago": "Just now",
            "count": 0
        }]
    
    return jsonify({
        "ok": True,
        "alerts": alerts,
        "total_count": len(alerts)
    })

def get_time_ago(dt):
    """Helper function to get human-readable time ago"""
    now = datetime.now()
    diff = now - dt
    
    if diff.total_seconds() < 60:
        return "Just now"
    elif diff.total_seconds() < 3600:
        minutes = int(diff.total_seconds() / 60)
        return f"{minutes} min ago"
    elif diff.total_seconds() < 86400:
        hours = int(diff.total_seconds() / 3600)
        return f"{hours} hour{'s' if hours > 1 else ''} ago"
    else:
        days = int(diff.total_seconds() / 86400)
        return f"{days} day{'s' if days > 1 else ''} ago"

@admin_bp.get("/api/inventory/status")
def api_inventory_status():
    """Get inventory system status"""
    try:
        # Get total products count
        total_products = db.session.query(Product).count()
        
        # Get total inventory items
        total_inventory = db.session.query(InventoryItem).count()
        
        # Get low stock items
        low_stock_count = db.session.query(InventoryItem).filter(
            InventoryItem.stock_kg < InventoryItem.warn_level
        ).count()
        
        return jsonify({
            "ok": True,
            "total_products": total_products,
            "total_inventory": total_inventory,
            "low_stock_count": low_stock_count,
            "status": "operational"
        })
    except Exception as e:
        return jsonify({
            "ok": False,
            "error": str(e),
            "status": "error"
        }), 500

@admin_bp.get("/api/forecast/status")
def api_forecast_status():
    """Get forecast engine status"""
    try:
        from sqlalchemy import func
        from datetime import datetime, timedelta
        
        # Get total forecasts
        total_forecasts = db.session.query(ForecastData).count()
        
        # Get active models (forecasts from last 30 days)
        recent_forecasts = db.session.query(ForecastData).filter(
            ForecastData.created_at >= datetime.now() - timedelta(days=30)
        ).count()
        
        # Get average accuracy
        avg_accuracy = db.session.query(func.avg(ForecastData.accuracy_score)).scalar() or 0
        
        return jsonify({
            "ok": True,
            "model_count": recent_forecasts,
            "total_forecasts": total_forecasts,
            "avg_accuracy": round(avg_accuracy, 2),
            "status": "operational"
        })
    except Exception as e:
        return jsonify({
            "ok": False,
            "error": str(e),
            "status": "error"
        }), 500
# =========================================================
# API: USER MANAGEMENT
# =========================================================
@admin_bp.get("/api/users")
def api_get_users():
    """Get all users with branch information"""
    try:
        users = db.session.query(User, Branch).outerjoin(Branch, User.branch_id == Branch.id).all()
        
        user_data = []
        for user, branch in users:
            user_data.append({
                "id": user.id,
                "email": user.email,
                "role": user.role,
                "branch_id": user.branch_id,
                "branch_name": branch.name if branch else "No Branch",
                "location": branch.location if branch else "N/A",
                "warehouse_id": f"WH-{user.id:03d}",  # Generate warehouse ID
                "contact_number": "N/A",  # Not stored in current schema
                "name": user.email.split('@')[0].replace('_', ' ').title()  # Generate name from email
            })
        
        return jsonify({
            "ok": True,
            "data": user_data
        })
    except Exception as e:
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.post("/api/users")
def api_create_user():
    """Create a new user"""
    try:
        data = request.get_json()
        
        # Validate required fields
        if not data.get('email') or not data.get('role'):
            return jsonify({
                "ok": False,
                "error": "Email and role are required"
            }), 400
        
        # Password is required on create
        password = data.get('password')
        if not password:
            return jsonify({
                "ok": False,
                "error": "Password is required"
            }), 400
        if len(password) < 8:
            return jsonify({
                "ok": False,
                "error": "Password must be at least 8 characters"
            }), 400
        
        # Check if email already exists
        existing_user = User.query.filter_by(email=data['email']).first()
        if existing_user:
            return jsonify({
                "ok": False,
                "error": "Email already exists"
            }), 400
        
        # Get branch if specified
        branch_id = None
        if data.get('branch_name'):
            branch = Branch.query.filter_by(name=data['branch_name']).first()
            if branch:
                branch_id = branch.id
        
        # Create user
        from werkzeug.security import generate_password_hash
        new_user = User(
            email=data['email'],
            password_hash=generate_password_hash(password),
            role=data['role'],
            branch_id=branch_id
        )
        
        db.session.add(new_user)
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "user_id": new_user.id,
            "message": "User created successfully"
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.put("/api/users/<int:user_id>")
def api_update_user(user_id):
    """Update a user"""
    try:
        user = User.query.get_or_404(user_id)
        data = request.get_json()
        
        # Update fields if provided
        if 'email' in data:
            # Check if email already exists (excluding current user)
            existing = User.query.filter(User.email == data['email'], User.id != user_id).first()
            if existing:
                return jsonify({
                    "ok": False,
                    "error": "Email already exists"
                }), 400
            user.email = data['email']
        
        if 'role' in data:
            user.role = data['role']
        
        if 'branch_name' in data:
            if data['branch_name']:
                branch = Branch.query.filter_by(name=data['branch_name']).first()
                user.branch_id = branch.id if branch else None
            else:
                user.branch_id = None
        
        # Optional password change on edit
        if 'password' in data and data['password']:
            new_password = data['password']
            if len(new_password) < 8:
                return jsonify({
                    "ok": False,
                    "error": "Password must be at least 8 characters"
                }), 400
            from werkzeug.security import generate_password_hash
            user.password_hash = generate_password_hash(new_password)
        
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "message": "User updated successfully"
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.delete("/api/users/<int:user_id>")
def api_delete_user(user_id):
    """Delete a user"""
    try:
        user = User.query.get_or_404(user_id)
        
        # Don't allow deleting the main admin
        if user.email == "admin@gmc.com":
            return jsonify({
                "ok": False,
                "error": "Cannot delete main admin user"
            }), 400
        
        # Clean up dependent records to satisfy FK constraints
        try:
            # Delete password reset records for this user
            from models import PasswordReset, EmailVerification, ActivityLog
            PasswordReset.query.filter_by(user_id=user.id).delete(synchronize_session=False)
            # Delete pending email verification records
            EmailVerification.query.filter_by(user_id=user.id).delete(synchronize_session=False)
            # Keep activity logs but detach FK; preserve email for audit
            db.session.query(ActivityLog)\
                .filter(ActivityLog.user_id == user.id)\
                .update({"user_id": None, "user_email": user.email}, synchronize_session=False)
        except Exception:
            # Even if cleanup fails, proceed; outer except will handle rollback if needed
            pass
        
        db.session.delete(user)
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "message": "User deleted successfully"
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

# =========================================================
# API: SETTINGS & AUTH
# =========================================================
@admin_bp.get("/api/me")
def api_get_current_user():
    """Get current user profile"""
    try:
        # Get current user from session
        user_data = session.get('user')
        if not user_data:
            return jsonify({"ok": False, "error": "Not authenticated"}), 401
        
        user_id = user_data.get('id')
        if not user_id:
            return jsonify({"ok": False, "error": "Invalid session"}), 401
        
        user = User.query.get(user_id)
        if not user:
            return jsonify({"ok": False, "error": "User not found"}), 404
        
        # Get branch info if user has one
        branch_name = None
        if user.branch_id:
            branch = Branch.query.get(user.branch_id)
            branch_name = branch.name if branch else None
        
        return jsonify({
            "ok": True,
            "user": {
                "id": user.id,
                "email": user.email,
                "name": user.email.split('@')[0].replace('_', ' ').title(),
                "role": user.role,
                "branch_id": user.branch_id,
                "branch_name": branch_name
            }
        })
    except Exception as e:
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.patch("/api/users/me")
def api_update_current_user():
    """Update current user profile"""
    try:
        # CSRF validation
        csrf_token = request.headers.get('X-CSRFToken')
        if not csrf_token or csrf_token != session.get('csrf_token'):
            return jsonify({"ok": False, "error": "Invalid CSRF token"}), 403
        
        user_data = session.get('user')
        if not user_data:
            return jsonify({"ok": False, "error": "Not authenticated"}), 401
        
        user_id = user_data.get('id')
        if not user_id:
            return jsonify({"ok": False, "error": "Invalid session"}), 401
        
        user = User.query.get(user_id)
        if not user:
            return jsonify({"ok": False, "error": "User not found"}), 404
        
        data = request.get_json()
        
        # Update email if provided
        if 'email' in data:
            new_email = data['email'].strip()
            if new_email != user.email:
                # Check if email already exists
                existing = User.query.filter(User.email == new_email, User.id != user.id).first()
                if existing:
                    return jsonify({"ok": False, "error": "Email already exists"}), 409
                
                # Start email verification process
                return handle_email_change_request(user, new_email)
        
        # Note: Name is derived from email, so we don't store it separately
        # Branch updates would require additional logic
        
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "message": "Profile updated successfully"
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.post("/api/auth/change_password")
def api_change_password():
    """Change user password"""
    try:
        # CSRF validation
        csrf_token = request.headers.get('X-CSRFToken')
        if not csrf_token or csrf_token != session.get('csrf_token'):
            return jsonify({"ok": False, "error": "Invalid CSRF token"}), 403
        
        user_data = session.get('user')
        if not user_data:
            return jsonify({"ok": False, "error": "Not authenticated"}), 401
        
        user_id = user_data.get('id')
        if not user_id:
            return jsonify({"ok": False, "error": "Invalid session"}), 401
        
        user = User.query.get(user_id)
        if not user:
            return jsonify({"ok": False, "error": "User not found"}), 404
        
        data = request.get_json()
        current_password = data.get('current_password')
        new_password = data.get('new_password')
        confirm_password = data.get('confirm_password')
        
        # Validate inputs
        if not current_password:
            return jsonify({"ok": False, "error": "Current password is required"}), 400
        
        if not new_password:
            return jsonify({"ok": False, "error": "New password is required"}), 400
        
        if new_password != confirm_password:
            return jsonify({"ok": False, "error": "Passwords do not match"}), 400
        
        if len(new_password) < 8:
            return jsonify({"ok": False, "error": "Password must be at least 8 characters"}), 400
        
        # Verify current password (simplified - in production, use proper hashing)
        # For demo purposes, we'll just check if it's not empty
        if not current_password:
            return jsonify({"ok": False, "error": "Current password is incorrect"}), 400
        
        # Update password (in production, hash the password)
        from werkzeug.security import generate_password_hash
        user.password_hash = generate_password_hash(new_password)
        
        db.session.commit()
        
        return jsonify({
            "ok": True,
            "message": "Password changed successfully"
        })
    except Exception as e:
        db.session.rollback()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.route("/api/auth/reset", methods=["POST", "OPTIONS"])
def api_reset_password():
    """
    Send password reset link - NO CSRF REQUIRED (login page has no session)
    
    This endpoint is accessible from login pages which don't have active sessions.
    CSRF validation is NOT required because:
    1. Login pages don't have sessions, so CSRF tokens can't be validated
    2. This only sends a reset link via email - no data changes
    3. The reset link itself requires a valid token to actually reset the password
    """
    # Handle OPTIONS preflight for CORS
    if request.method == "OPTIONS":
        response = make_response()
        response.headers.add("Access-Control-Allow-Origin", "*")
        response.headers.add("Access-Control-Allow-Headers", "Content-Type")
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        return response
    
    # NO CSRF CHECK - This endpoint is intentionally accessible without CSRF
    # for password reset from login pages
    
    try:
        print("=" * 80)
        print("DEBUG ADMIN PASSWORD RESET: Endpoint CALLED - NO CSRF CHECK")
        print(f"DEBUG ADMIN PASSWORD RESET: Method = {request.method}")
        print(f"DEBUG ADMIN PASSWORD RESET: URL = {request.url}")
        print(f"DEBUG ADMIN PASSWORD RESET: Path = {request.path}")
        print(f"DEBUG ADMIN PASSWORD RESET: Endpoint = {request.endpoint}")
        print("=" * 80)
        
        data = request.get_json()
        print(f"DEBUG ADMIN PASSWORD RESET: Request data = {data}")
        email = data.get('email')
        
        if not email:
            return jsonify({"ok": False, "error": "Email is required"}), 400
        
        # Check if user exists
        user = User.query.filter_by(email=email).first()
        if not user:
            return jsonify({
                "ok": False,
                "error": "Email not found. Please check your email address and try again."
            }), 404
        
        # Generate a secure reset token
        import secrets
        reset_token = secrets.token_urlsafe(32)
        
        # Store reset token in database
        password_reset = PasswordReset(
            user_id=user.id,
            reset_token=reset_token,
            expires_at=datetime.utcnow() + timedelta(hours=1)
        )
        
        db.session.add(password_reset)
        db.session.commit()
        
        # Try to send reset email
        try:
            from email_service import email_service
            
            # Create reset link
            # Get base URL from request or environment
            base_url = os.getenv('BASE_URL')
            if not base_url or base_url.startswith('http://localhost') or base_url.startswith('http://127.0.0.1'):
                try:
                    base_url = request.host_url.rstrip('/')
                except:
                    base_url = os.getenv('BASE_URL', 'http://localhost:5000')
            reset_link = f"{base_url}/admin/reset-password?token={reset_token}"
            
            # Send reset email
            email_sent = email_service.send_password_reset_email(email, reset_token, user.email.split('@')[0].replace('_', ' ').title())
            
            if email_sent:
                return jsonify({
                    "ok": True,
                    "message": "Password reset link sent to your email"
                })
            else:
                # Fallback for demo mode
                return jsonify({
                    "ok": True,
                    "message": f"Email service not configured. For demo purposes, use this reset link: {reset_link}",
                    "demo_link": reset_link
                })
        except Exception as email_error:
            print(f"Email service error: {email_error}")
            # Fallback for demo mode
            # Get base URL from request or environment
            base_url = os.getenv('BASE_URL')
            if not base_url or base_url.startswith('http://localhost') or base_url.startswith('http://127.0.0.1'):
                try:
                    base_url = request.host_url.rstrip('/')
                except:
                    base_url = os.getenv('BASE_URL', 'http://localhost:5000')
            reset_link = f"{base_url}/admin/reset-password?token={reset_token}"
            
            return jsonify({
                "ok": True,
                "message": f"Email service error. For demo purposes, use this reset link: {reset_link}",
                "demo_link": reset_link
            })
    except Exception as e:
        print(f"DEBUG ADMIN PASSWORD RESET: Exception occurred: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.post("/api/auth/confirm_reset")
def api_confirm_password_reset():
    """Confirm password reset with token"""
    try:
        data = request.get_json()
        token = data.get('token')
        new_password = data.get('new_password')
        
        if not token:
            return jsonify({"ok": False, "error": "Reset token is required"}), 400
        
        if not new_password:
            return jsonify({"ok": False, "error": "New password is required"}), 400
        
        if len(new_password) < 8:
            return jsonify({"ok": False, "error": "Password must be at least 8 characters"}), 400
        
        # Check if token is valid in database
        password_reset = PasswordReset.query.filter_by(
            reset_token=token,
            is_used=False
        ).first()
        
        if not password_reset:
            return jsonify({"ok": False, "error": "Invalid or expired reset token"}), 400
        
        # Check if expired
        if password_reset.is_expired():
            # Delete expired reset record
            db.session.delete(password_reset)
            db.session.commit()
            return jsonify({"ok": False, "error": "Reset token has expired"}), 400
        
        # Find user by ID
        user = User.query.get(password_reset.user_id)
        if not user:
            return jsonify({"ok": False, "error": "User not found"}), 404
        
        # Update password
        from werkzeug.security import generate_password_hash
        user.password_hash = generate_password_hash(new_password)
        
        # Mark reset as used
        password_reset.is_used = True
        
        db.session.commit()
        
        # Log the password reset activity
        from activity_logger import ActivityLogger
        ActivityLogger.log_password_reset(user.email, success=True)
        
        return jsonify({
            "ok": True,
            "message": "Password reset successfully"
        })
        
    except Exception as e:
        db.session.rollback()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

# =========================================================
# EMAIL VERIFICATION FUNCTIONS
# =========================================================
def handle_email_change_request(user, new_email):
    """Handle email change request with verification"""
    try:
        from email_service import email_service
        import secrets
        
        # Generate verification token
        verification_token = secrets.token_urlsafe(32)
        
        # Create verification record
        verification = EmailVerification(
            user_id=user.id,
            new_email=new_email,
            verification_token=verification_token,
            expires_at=datetime.utcnow() + timedelta(hours=24)
        )
        
        db.session.add(verification)
        db.session.commit()
        
        # Send verification email (with fallback for demo)
        user_name = user.email.split('@')[0].replace('_', ' ').title()
        
        try:
            # Check if email service is configured
            if not email_service.is_configured:
                print("Email service not configured - providing demo link")
                # Get base URL from request or environment
                base_url = os.getenv('BASE_URL')
                if not base_url or base_url.startswith('http://localhost') or base_url.startswith('http://127.0.0.1'):
                    try:
                        base_url = request.host_url.rstrip('/')
                    except:
                        base_url = os.getenv('BASE_URL', 'http://localhost:5000')
                verification_link = f"{base_url}/admin/verify-email?token={verification_token}"
                
                return jsonify({
                    "ok": True,
                    "message": f"Email service not configured. For demo purposes, click this link to verify: {verification_link}",
                    "requires_verification": True,
                    "demo_link": verification_link
                })
            
            # Try to send real email
            email_sent = email_service.send_verification_email(
                new_email, 
                verification_token, 
                user_name
            )
            
            if email_sent:
                return jsonify({
                    "ok": True,
                    "message": "Verification email sent to your new email address. Please check your inbox and click the verification link to complete the change.",
                    "requires_verification": True
                })
            else:
                # If email fails, provide manual verification link for demo
                # Get base URL from request or environment
                base_url = os.getenv('BASE_URL')
                if not base_url or base_url.startswith('http://localhost') or base_url.startswith('http://127.0.0.1'):
                    try:
                        base_url = request.host_url.rstrip('/')
                    except:
                        base_url = os.getenv('BASE_URL', 'http://localhost:5000')
                verification_link = f"{base_url}/admin/verify-email?token={verification_token}"
                
                return jsonify({
                    "ok": True,
                    "message": f"Failed to send email. For demo purposes, click this link to verify: {verification_link}",
                    "requires_verification": True,
                    "demo_link": verification_link
                })
        except Exception as email_error:
            print(f"Email service error: {email_error}")
            # Provide manual verification link for demo
            base_url = os.getenv('BASE_URL', 'http://localhost:5000')
            verification_link = f"{base_url}/admin/verify-email?token={verification_token}"
            
            return jsonify({
                "ok": True,
                "message": f"Email service error. For demo purposes, click this link to verify: {verification_link}",
                "requires_verification": True,
                "demo_link": verification_link
            })
            
    except Exception as e:
        db.session.rollback()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500

@admin_bp.get("/reset-password")
def reset_password():
    """Password reset page"""
    try:
        token = request.args.get('token')
        if not token:
            return render_template_string("""
                <html>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #d32f2f;">Invalid Reset Link</h1>
                    <p>The password reset link is invalid or missing.</p>
                    <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
                </body>
                </html>
            """)
        
        # Check if token is valid in database
        password_reset = PasswordReset.query.filter_by(
            reset_token=token,
            is_used=False
        ).first()
        
        # Debug logging
        print(f"DEBUG RESET: Token from URL: {token}")
        print(f"DEBUG RESET: Found in DB: {password_reset is not None}")
        if password_reset:
            print(f"DEBUG RESET: User ID: {password_reset.user_id}")
            print(f"DEBUG RESET: Expires at: {password_reset.expires_at}")
            print(f"DEBUG RESET: Is expired: {password_reset.is_expired()}")
        
        if not password_reset:
            return render_template_string("""
                <html>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #d32f2f;">Invalid Reset Link</h1>
                    <p>The password reset link is invalid or has expired.</p>
                    <p>Debug: Token mismatch or not found in session.</p>
                    <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
                </body>
                </html>
            """)
        
        # Check if expired
        if password_reset.is_expired():
            # Delete expired reset record
            db.session.delete(password_reset)
            db.session.commit()
            
            return render_template_string("""
                <html>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #d32f2f;">Reset Link Expired</h1>
                    <p>The password reset link has expired. Please request a new one.</p>
                    <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
                </body>
                </html>
            """)
        
        # Show password reset form
        return render_template_string("""
            <html>
            <body style="font-family: Arial, sans-serif; max-width: 500px; margin: 50px auto; padding: 20px;">
                <div style="background: #f9f9f9; padding: 30px; border-radius: 8px;">
                    <h1 style="color: #2e7d32; text-align: center;">Reset Password</h1>
                    <p style="text-align: center; color: #666;">Enter your new password below:</p>
                    
                    <form id="resetForm" style="margin-top: 20px;">
                        <div style="margin-bottom: 15px;">
                            <label style="display: block; margin-bottom: 5px; font-weight: bold;">New Password:</label>
                            <input type="password" id="newPassword" required 
                                   style="width: 100%; padding: 10px; border: 1px solid #ddd; border-radius: 4px; box-sizing: border-box;">
                        </div>
                        <div style="margin-bottom: 20px;">
                            <label style="display: block; margin-bottom: 5px; font-weight: bold;">Confirm Password:</label>
                            <input type="password" id="confirmPassword" required 
                                   style="width: 100%; padding: 10px; border: 1px solid #ddd; border-radius: 4px; box-sizing: border-box;">
                        </div>
                        <button type="submit" style="width: 100%; background: #2e7d32; color: white; padding: 12px; border: none; border-radius: 4px; cursor: pointer; font-size: 16px;">
                            Reset Password
                        </button>
                    </form>
                    
                    <div id="message" style="margin-top: 15px; text-align: center; display: none;"></div>
                </div>
                
                <script>
                document.getElementById('resetForm').addEventListener('submit', async function(e) {
                    e.preventDefault();
                    
                    const newPassword = document.getElementById('newPassword').value;
                    const confirmPassword = document.getElementById('confirmPassword').value;
                    const messageDiv = document.getElementById('message');
                    
                    if (newPassword !== confirmPassword) {
                        messageDiv.textContent = 'Passwords do not match!';
                        messageDiv.style.color = '#d32f2f';
                        messageDiv.style.display = 'block';
                        return;
                    }
                    
                    if (newPassword.length < 8) {
                        messageDiv.textContent = 'Password must be at least 8 characters!';
                        messageDiv.style.color = '#d32f2f';
                        messageDiv.style.display = 'block';
                        return;
                    }
                    
                    try {
                        const response = await fetch('/admin/api/auth/confirm_reset', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify({
                                token: '{{ token }}',
                                new_password: newPassword
                            })
                        });
                        
                        const data = await response.json();
                        
                        if (data.ok) {
                            messageDiv.textContent = 'Password reset successfully! You can now log in with your new password.';
                            messageDiv.style.color = '#2e7d32';
                            messageDiv.style.display = 'block';
                            
                            // Clear form
                            document.getElementById('resetForm').reset();
                            
                            // Redirect to login after 3 seconds
                            setTimeout(() => {
                                window.location.href = '/admin-login';
                            }, 3000);
                        } else {
                            messageDiv.textContent = 'Error: ' + data.error;
                            messageDiv.style.color = '#d32f2f';
                            messageDiv.style.display = 'block';
                        }
                    } catch (error) {
                        messageDiv.textContent = 'Error resetting password. Please try again.';
                        messageDiv.style.color = '#d32f2f';
                        messageDiv.style.display = 'block';
                    }
                });
                </script>
            </body>
            </html>
        """, token=token)
        
    except Exception as e:
        return render_template_string("""
            <html>
            <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                <h1 style="color: #d32f2f;">Reset Failed</h1>
                <p>An error occurred during password reset: {{ error }}</p>
                <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
            </body>
            </html>
        """, error=str(e))

@admin_bp.get("/verify-email")
def verify_email():
    """Verify email change"""
    try:
        token = request.args.get('token')
        if not token:
            return render_template_string("""
                <html>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #d32f2f;">Invalid Verification Link</h1>
                    <p>The verification link is invalid or missing.</p>
                    <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
                </body>
                </html>
            """)
        
        # Find verification record
        verification = EmailVerification.query.filter_by(
            verification_token=token,
            is_verified=False
        ).first()
        
        if not verification:
            return render_template_string("""
                <html>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #d32f2f;">Invalid Verification Link</h1>
                    <p>The verification link is invalid or has already been used.</p>
                    <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
                </body>
                </html>
            """)
        
        # Check if expired
        if verification.is_expired():
            db.session.delete(verification)
            db.session.commit()
            return render_template_string("""
                <html>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #d32f2f;">Verification Link Expired</h1>
                    <p>The verification link has expired. Please request a new email change.</p>
                    <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
                </body>
                </html>
            """)
        
        # Get user
        user = User.query.get(verification.user_id)
        if not user:
            return render_template_string("""
                <html>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #d32f2f;">User Not Found</h1>
                    <p>The user associated with this verification link was not found.</p>
                    <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
                </body>
                </html>
            """)
        
        # Update user email
        old_email = user.email
        user.email = verification.new_email
        
        # Mark verification as completed
        verification.is_verified = True
        
        db.session.commit()
        
        # Log the email change activity
        from activity_logger import ActivityLogger
        ActivityLogger.log_email_change(user.email, old_email, user.email, success=True)
        
        # Update session with new email
        if session.get('user'):
            session['user']['email'] = verification.new_email
            session.modified = True
            print(f"DEBUG: Updated session email to {verification.new_email}")
        
        # Send notification to old email
        try:
            from email_service import email_service
            user_name = old_email.split('@')[0].replace('_', ' ').title()
            email_service.send_email_change_notification(
                old_email, 
                verification.new_email, 
                user_name
            )
        except Exception as e:
            print(f"Failed to send notification email: {e}")
        
        # Clean up verification record
        db.session.delete(verification)
        db.session.commit()
        
        return render_template_string("""
            <html>
            <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                <div style="max-width: 500px; margin: 0 auto; background: #f9f9f9; padding: 30px; border-radius: 8px;">
                    <h1 style="color: #2e7d32;">Email Successfully Verified!</h1>
                    <p>Your email address has been successfully changed to:</p>
                    <p style="background: #e8f5e8; padding: 10px; border-radius: 4px; font-family: monospace;">{{ new_email }}</p>
                    <p>You can now log in using your new email address.</p>
                    <a href="/admin/settings" style="background: #2e7d32; color: white; padding: 10px 20px; text-decoration: none; border-radius: 4px;">Return to Settings</a>
                </div>
            </body>
            </html>
        """, new_email=verification.new_email)
        
    except Exception as e:
        db.session.rollback()
        return render_template_string("""
            <html>
            <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                <h1 style="color: #d32f2f;">Verification Failed</h1>
                <p>An error occurred during email verification: {{ error }}</p>
                <a href="/admin/settings" style="color: #2e7d32;">Return to Settings</a>
            </body>
            </html>
        """, error=str(e))
